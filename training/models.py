import numpy as np
from numpy.lib.type_check import imag
import torch
import torch.nn as nn
from torch_utils import misc
from torch_utils import persistence
from torch_utils.ops import conv2d_resample
from torch_utils.ops import upfirdn2d
from torch_utils.ops import bias_act
from torch_utils.ops import fma
from icecream import ic
import torch.nn.functional as F
from training.ffc import FFCResnetBlock, ConcatTupleLayer


from training.DSC import DepthwiseSeparableConv
from training.ECA import ECALayer
from training.mdta import MDTA  # å¯¼å…¥ MDTA æ¨¡å—


# ----------------------------------------------------------------------------
'''
class ReconstructionModule(nn.Module):
    def __init__(self, img_channels):
        super(ReconstructionModule, self).__init__()
        self.conv1 = nn.Conv2d(img_channels, 64, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(128, img_channels, kernel_size=3, padding=1)
        self.relu = nn.ReLU()
        self.pool = nn.MaxPool2d(2, 2)

    def forward(self, x):
        x = self.relu(self.conv1(x))
        x = self.pool(x)
        x = self.relu(self.conv2(x))
        x = self.pool(x)
        x = self.conv3(x)
        return x
'''

@misc.profiled_function
# å¯¹å¼ é‡ x è¿›è¡ŒäºŒé˜¶çŸ©å½’ä¸€åŒ–ï¼Œç¡®ä¿å…¶åœ¨æŒ‡å®šç»´åº¦ä¸Šçš„å¹³æ–¹å‡å€¼ä¸º 1ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒé€šè¿‡è°ƒæ•´å¼ é‡çš„å¹…åº¦ï¼ˆå¤§å°ï¼‰æ¥ä½¿å…¶å…·æœ‰å‡åŒ€çš„åˆ†å¸ƒ
def normalize_2nd_moment(x, dim=1, eps=1e-8):  # dim: è¦è¿›è¡Œå½’ä¸€åŒ–çš„ç»´åº¦ï¼Œé»˜è®¤ä¸º 1ï¼ˆé€šå¸¸æ˜¯é€šé“ç»´åº¦;eps: ä¸€ä¸ªå°å¸¸æ•°ï¼Œç”¨æ¥é˜²æ­¢é™¤ä»¥é›¶çš„æƒ…å†µ
    return x * (x.square().mean(dim=dim, keepdim=True) + eps).rsqrt()  # é¦–å…ˆå¯¹å¼ é‡ x çš„æ¯ä¸ªå…ƒç´ è¿›è¡Œå¹³æ–¹è®¡ç®—ï¼Œæ²¿ç€æŒ‡å®šçš„ dim ç»´åº¦è®¡ç®—å¹³æ–¹åçš„å‡å€¼ã€‚


# keepdim=True ä¿è¯è®¡ç®—åçš„å¼ é‡ä¿æŒåŸæ¥çš„ç»´åº¦æ•°ï¼Œé¿å…é™ç»´ï¼›ä¸ºäº†é˜²æ­¢åç»­é™¤ä»¥é›¶çš„æƒ…å†µï¼Œæ·»åŠ ä¸€ä¸ªéå¸¸å°çš„å¸¸æ•°epsï¼Œé€šè¿‡.rsqrt() è®¡ç®—å¹³æ–¹æ ¹çš„å€’æ•°ï¼ˆé€†å¹³æ–¹æ ¹ï¼‰ã€‚
# è¿™ç›¸å½“äº 1 / sqrt(...)ï¼Œå¯ä»¥ç”¨äºç¼©æ”¾åŸå§‹å¼ é‡ï¼Œæœ€åï¼Œå°†åŸå§‹å¼ é‡ x ä¸è®¡ç®—å‡ºæ¥çš„é€†å¹³æ–¹æ ¹ç›¸ä¹˜ã€‚è¿™ä¸€æ­¥å°†è°ƒæ•´ x çš„å¹…åº¦ï¼Œä½¿å¾—å®ƒçš„å¹³æ–¹å‡å€¼ä¸º 1ï¼Œå³äºŒé˜¶çŸ©è¢«å½’ä¸€åŒ–
@misc.profiled_function
def modulated_conv2d(
        x,  # Input tensor of shape [batch_size, in_channels, in_height, in_width].
        weight,  # Weightå·ç§¯æ ¸æƒé‡å¼ é‡ tensor of shape [out_channels, in_channels, kernel_height, kernel_width].
        styles,  # Modulation coefficients é£æ ¼è°ƒåˆ¶ç³»æ•° of shape [batch_size, in_channels].
        noise=None,  # Optional noise tensor to add to the output activations.åœ¨å·ç§¯ç»“æœä¸Šå¢åŠ å™ªå£°
        up=1,  # Integer upsampling factor.ä¸Šé‡‡æ ·å› å­ã€‚é»˜è®¤å€¼ä¸º 1ï¼ˆä¸è¿›è¡Œä¸Šé‡‡æ ·
        down=1,  # Integer downsampling factor.ä¸‹é‡‡æ ·å› å­ã€‚é»˜è®¤å€¼ä¸º 1ï¼ˆä¸è¿›è¡Œä¸‹é‡‡æ ·
        padding=0,  # Padding with respect to the upsampled image.å·ç§¯æ“ä½œä¸­çš„å¡«å……ï¼Œä¿è¯å·ç§¯ä¸æ”¹å˜å›¾åƒå°ºå¯¸
        resample_filter=None,
        # ä½é€šæ»¤æ³¢å™¨ to apply when resampling activations. Must be prepared beforehand by calling upfirdn2d.setup_filter().
        demodulate=True,  # Apply weight demodulation?æ˜¯å¦åœ¨å·ç§¯è¿‡ç¨‹ä¸­åº”ç”¨å»è°ƒåˆ¶æ“ä½œã€‚å»è°ƒåˆ¶æ˜¯ä¸ºäº†é¿å…ç‰¹å¾å›¾çš„æ”¾å¤§æˆ–ç¼©å°ä¸å‡è¡¡ã€‚
        flip_weight=True,
        # False = convolution, True = correlation (matches torch.nn.functional.conv2d).æ§åˆ¶å·ç§¯ç±»å‹ï¼ŒFalæ ‡å‡†å·ç§¯ï¼ŒTrç›¸å…³æ“ä½œ
        fused_modconv=True,
        # Perform modulation, convolution, and demodulation as a single fused operation?æ˜¯å¦å°†è°ƒåˆ¶ã€å·ç§¯å’Œå»è°ƒåˆ¶ä½œä¸ºä¸€ä¸ªå•ç‹¬çš„æ“ä½œæ¥æ‰§è¡Œ
):
    batch_size = x.shape[0]
    out_channels, in_channels, kh, kw = weight.shape  # ç¡®ä¿è¾“å…¥çš„å¼ é‡ weightã€x å’Œ styles å…·æœ‰æ­£ç¡®çš„å½¢çŠ¶
    misc.assert_shape(weight, [out_channels, in_channels, kh, kw])  # [OIkk]
    misc.assert_shape(x, [batch_size, in_channels, None, None])  # [NIHW]
    misc.assert_shape(styles, [batch_size, in_channels])  # [NI]

    # Pre-normalize inputs to avoid FP16 overflow.å¦‚æœè¾“å…¥æ•°æ®ç±»å‹æ˜¯ float16ï¼Œä¸ºäº†é¿å…æ•°å€¼è¿‡å¤§å¯¼è‡´æº¢å‡ºï¼Œå¯¹ weight å’Œ styles è¿›è¡Œå½’ä¸€åŒ–
    if x.dtype == torch.float16 and demodulate:
        weight = weight * (1 / np.sqrt(in_channels * kh * kw) / weight.norm(float('inf'), dim=[1, 2, 3],
                                                                            keepdim=True))  # max_Ikk
        styles = styles / styles.norm(float('inf'), dim=1, keepdim=True)  # max_I

    # Calculate per-sample weights and demodulation coefficients.åˆ†åˆ«ç”¨äºå­˜å‚¨è°ƒåˆ¶åçš„æƒé‡å’Œå»è°ƒåˆ¶ç³»æ•°
    w = None
    dcoefs = None
    if demodulate or fused_modconv:
        w = weight.unsqueeze(0)  # [NOIkk]å°†å·ç§¯æ ¸çš„æƒé‡æ‰©å±•ä¸€ä¸ªæ‰¹æ¬¡ç»´åº¦ï¼Œå¹¶æ ¹æ®æ ·æœ¬çš„é£æ ¼ç³»æ•°å¯¹æƒé‡è¿›è¡Œè°ƒåˆ¶
        w = w * styles.reshape(batch_size, 1, -1, 1, 1)  # [NOIkk]å…¶ä¸­ N æ˜¯ batch_sizeï¼Œkï¼šè¡¨ç¤º kernel sizeï¼Œå³å·ç§¯æ ¸çš„å¤§å°
    # ä½¿å½¢çŠ¶ä»[out_channels, in_channels, kernel_height, kernel_width]å˜[1, out_channels, in_channels, kh, kw]ï¼Œ1ä»£è¡¨batchç»´åº¦
    # ä½¿ç”¨é£æ ¼è°ƒåˆ¶ç³»æ•° styles å¯¹æƒé‡è¿›è¡Œé€æ ·æœ¬çš„è°ƒåˆ¶ã€‚styles æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º [batch_size, in_channels] çš„å¼ é‡ï¼Œè¡¨ç¤ºæ¯ä¸ªæ ·æœ¬æ¯ä¸ªè¾“å…¥é€šé“çš„é£æ ¼è°ƒåˆ¶ç³»æ•°
    if demodulate:  # å¯ç”¨äº†å»è°ƒåˆ¶ï¼ˆdemodulate=Trueï¼‰ï¼Œåˆ™è®¡ç®— dcoefsï¼Œå³å»è°ƒåˆ¶ç³»æ•°ã€‚å»è°ƒåˆ¶çš„ç›®çš„æ˜¯æ¶ˆé™¤æ¯ä¸ªæ ·æœ¬çš„æƒé‡è¿‡å¤§æˆ–è¿‡å°çš„å½±å“ï¼Œé˜²æ­¢ä¸å¹³è¡¡
        dcoefs = (w.square().sum(dim=[2, 3, 4]) + 1e-8).rsqrt()  # [NO]å¯¹æƒé‡çš„å¹³æ–¹å’Œæ±‚å’Œåï¼ŒåŠ ä¸Šä¸€ä¸ªå°çš„æ•°å€¼1e-8ï¼Œè®¡ç®—å¹³æ–¹å’Œçš„å¹³æ–¹æ ¹çš„å€’æ•°rsqrtï¼Œå¾—åˆ°å»è°ƒåˆ¶ç³»æ•°
    if demodulate and fused_modconv:  # å»è°ƒåˆ¶å’Œèåˆå·ç§¯æ“ä½œéƒ½å¯ç”¨ï¼Œæ ¹æ®å»è°ƒåˆ¶ç³»æ•° dcoefs å¯¹è°ƒåˆ¶åçš„æƒé‡è¿›è¡Œç¼©æ”¾ã€‚
        # dcoefs çš„å½¢çŠ¶ä¸º [batch_size, out_channels]ï¼Œåœ¨è¿™é‡Œè¢«è°ƒæ•´æˆ [batch_size, out_channels, 1, 1, 1]ï¼Œä»¥ä¾¿ä¸æƒé‡çš„å½¢çŠ¶åŒ¹é…
        w = w * dcoefs.reshape(batch_size, -1, 1, 1, 1)  # [NOIkk]
    # Execute by scaling the activations before and after the convolution.é¦–å…ˆå¯¹è¾“å…¥ x è¿›è¡Œé£æ ¼è°ƒåˆ¶ï¼Œç„¶åæ‰§è¡Œå·ç§¯æ“ä½œã€‚
    if not fused_modconv:  # styleç»è¿‡è°ƒæ•´åï¼Œä¸è¾“å…¥å¼ é‡xç›¸ä¹˜ï¼Œè°ƒåˆ¶è¾“å…¥çš„ç‰¹å¾å›¾ï¼Œconv2d_resampleæ˜¯æ‰§è¡Œå·ç§¯çš„æ“ä½œï¼Œå®ƒæ”¯æŒä¸Šé‡‡æ ·upã€ä¸‹é‡‡æ ·downå’Œè‡ªå®šä¹‰æ»¤æ³¢å™¨resa_filter
        x = x * styles.to(x.dtype).reshape(batch_size, -1, 1, 1)
        x = conv2d_resample.conv2d_resample(x=x, w=weight.to(x.dtype), f=resample_filter, up=up, down=down,
                                            padding=padding, flip_weight=flip_weight)
        if demodulate and noise is not None:  # å¯ç”¨äº†å»è°ƒåˆ¶å¹¶ä¸”æœ‰å™ªå£°ï¼Œåˆ™å°†å™ªå£°å’Œå»è°ƒåˆ¶ç³»æ•°ä¸€èµ·åº”ç”¨åˆ°å·ç§¯ç»“æœ x ä¸Š
            x = fma.fma(x, dcoefs.to(x.dtype).reshape(batch_size, -1, 1, 1), noise.to(x.dtype))
        elif demodulate:  # æ²¡æœ‰å™ªå£°ï¼Œä½†å¯ç”¨äº†å»è°ƒåˆ¶ï¼Œåˆ™ä»…åº”ç”¨å»è°ƒåˆ¶ç³»æ•°
            x = x * dcoefs.to(x.dtype).reshape(batch_size, -1, 1, 1)
        elif noise is not None:  # åªæœ‰å™ªå£°ï¼Œæ²¡æœ‰å»è°ƒåˆ¶ï¼Œåˆ™åªåŠ ä¸Šå™ªå£°
            x = x.add_(noise.to(x.dtype))
        return x

    # Execute as one fused op using grouped convolution.
    with misc.suppress_tracer_warnings():  # this value will be treated as a constant
        batch_size = int(batch_size)
    misc.assert_shape(x, [batch_size, in_channels, None, None])
    x = x.reshape(1, -1, *x.shape[2:])  # é‡å¡‘è¾“å…¥ä¸ºå•æ‰¹æ¬¡çš„å¤šé€šé“è¾“å…¥
    w = w.reshape(-1, in_channels, kh, kw)  # é‡å¡‘æƒé‡ï¼›ï¼›ä½¿ç”¨æ‰¹æ¬¡ç»´åº¦ä½œä¸ºåˆ†ç»„groups=batch_size
    x = conv2d_resample.conv2d_resample(x=x, w=w.to(x.dtype), f=resample_filter, up=up, down=down, padding=padding,
                                        groups=batch_size, flip_weight=flip_weight)
    x = x.reshape(batch_size, -1, *x.shape[2:])
    if noise is not None:
        x = x.add_(noise)
    return x


# ----------------------------------------------------------------------------

@persistence.persistent_class
class FullyConnectedLayer(torch.nn.Module):  # å…¨è¿æ¥å±‚ï¼ˆFullyConnectedLayerï¼‰ï¼Œç”¨äºç¥ç»ç½‘ç»œä¸­çš„å‰å‘ä¼ æ’­
    def __init__(self,
                 in_features,  # Number of input features
                 out_features,  # Number of output features.
                 bias=True,  # Apply additive bias before the activation function?æ˜¯å¦åœ¨æ¿€æ´»å‡½æ•°ä¹‹å‰åº”ç”¨åç½®
                 activation='linear',  # Activation function: 'relu', 'lrelu', etc.æ¿€æ´»å‡½æ•°ï¼Œé»˜è®¤æ˜¯ 'linear'çº¿æ€§ï¼ˆæ— æ¿€æ´»ï¼‰
                 lr_multiplier=1,  # Learning rate multiplier.å­¦ä¹ ç‡å€ç‡ï¼Œå½±å“å‚æ•°æ›´æ–°çš„é€Ÿåº¦ï¼Œä¹Ÿä¼šå½±å“æƒé‡å’Œåç½®çš„åˆå§‹åŒ–
                 bias_init=0,  # Initial value for the additive bias.åç½®çš„åˆå§‹å€¼
                 ):
        super().__init__()
        self.activation = activation
        self.weight = torch.nn.Parameter(torch.randn(
            [out_features, in_features]) / lr_multiplier)  # æƒé‡çŸ©é˜µï¼Œå½¢çŠ¶[out_fea, in_fea]ï¼Œé€šè¿‡torch.randnéšæœºåˆå§‹åŒ–ï¼Œå¹¶é™¤lræ¥æ§åˆ¶åˆå§‹å€¼çš„èŒƒå›´
        self.bias = torch.nn.Parameter(
            torch.full([out_features], np.float32(bias_init))) if bias else None  # å½¢çŠ¶ä¸º[out_features]ï¼Œæ ¹æ® bias_init çš„å€¼åˆå§‹åŒ–
        self.weight_gain = lr_multiplier / np.sqrt(in_features)  # å­¦ä¹ ç‡å€ç‡å½±å“æƒé‡æ›´æ–°çš„å°ºåº¦
        self.bias_gain = lr_multiplier  # åç½®çš„å­¦ä¹ ç‡å€ç‡ï¼Œé€šè¿‡ lr_multiplier æ¥æ§åˆ¶

    def forward(self, x):
        w = self.weight.to(
            x.dtype) * self.weight_gain  # æƒé‡self.weightè¢«è½¬æ¢ä¸ºè¾“å…¥æ•°æ®xçš„æ•°æ®ç±»å‹ï¼ˆfloat32æˆ–float16ï¼‰ï¼Œå¹¶ä¹˜weight_gainï¼Œç¡®ä¿æƒé‡æ›´æ–°æ—¶çš„å°ºåº¦ä¸å­¦ä¹ ç‡å€ç‡ç›¸åŒ¹é…
        b = self.bias
        if b is not None:  # å°†åç½®è½¬æ¢ä¸ºä¸è¾“å…¥ç›¸åŒçš„æ•°æ®ç±»å‹
            b = b.to(x.dtype)
            if self.bias_gain != 1:
                b = b * self.bias_gain  # éœ€è¦å¯¹åç½®è¿›è¡Œç¼©æ”¾
        # ä½¿ç”¨ torch.addmmï¼Œè¿™æ˜¯ä¸€ç§é«˜æ•ˆçš„çŸ©é˜µä¹˜æ³•ä¸åŠ æ³•æ“ä½œï¼Œè®¡ç®—å…¬å¼ä¸º x = x @ w.T + bã€‚w.t() æ˜¯æƒé‡çŸ©é˜µçš„è½¬ç½®æ“ä½œã€‚b.unsqueeze(0) å°†åç½®æ‰©å±•ä¸€ä¸ªç»´åº¦ä»¥ä¾¿ä¸çŸ©é˜µåŠ æ³•åŒ¹é…
        if self.activation == 'linear' and b is not None:
            x = torch.addmm(b.unsqueeze(0), x, w.t())
        else:
            x = x.matmul(w.t())  # ç›´æ¥è¿›è¡ŒçŸ©é˜µä¹˜æ³• x @ w.Tï¼Œä¸åŠ åç½®
            x = bias_act.bias_act(x, b,
                                  act=self.activation)  # ç”¨bias_act.bias_actå‡½æ•°ï¼Œå°†åç½®bå’Œæ¿€æ´»å‡½æ•°åº”ç”¨äºè¾“å‡º xã€‚æ¿€æ´»å‡½æ•°çš„ç±»å‹ç”±self.activationå†³å®š
        return x


# ----------------------------------------------------------------------------

@persistence.persistent_class
class Conv2dLayer(torch.nn.Module):
    def __init__(self,
                 in_channels,  # Number of input channels.
                 out_channels,  # Number of output channels.
                 kernel_size,  # Width and height of the convolution kernel.
                 bias=True,  # Apply additive bias before the activation function?
                 activation='linear',  # Activation function: 'relu', 'lrelu', etc.
                 up=1,  # Integer upsampling factor.
                 down=1,  # Integer downsampling factor.é»˜è®¤ä¸ä¸‹é‡‡æ ·
                 resample_filter=[1, 3, 3, 1],
                 # Low-pass filter to apply when resampling activations.ç”¨äºä¸Š/ä¸‹é‡‡æ ·çš„ä½é€šæ»¤æ³¢å™¨ï¼ˆé»˜è®¤ä¸º [1, 3, 3, 1]
                 conv_clamp=None,  # Clamp the output to +-X, None = disable clamping.æ˜¯å¦å°†å·ç§¯ç»“æœè£å‰ªåˆ°æŸä¸ªèŒƒå›´å†…
                 channels_last=False,  # Expect the input to have memory_format=channels_last?æ˜¯å¦ä½¿ç”¨ channels_last å†…å­˜æ ¼å¼ï¼ˆ
                 trainable=True,  # Update the weights of this layer during training?æ˜¯å¦åœ¨è®­ç»ƒæœŸé—´æ›´æ–°æƒé‡ï¼ˆé»˜è®¤ä¸º Trueï¼Œè¡¨ç¤ºè¯¥å±‚çš„æƒé‡å¯è®­ç»ƒï¼‰
                 ):
        super().__init__()
        self.activation = activation
        self.up = up
        self.down = down
        self.conv_clamp = conv_clamp
        self.register_buffer('resample_filter', upfirdn2d.setup_filter(resample_filter))  # å°†ä½é€šæ»¤æ³¢å™¨æ³¨å†Œä¸ºå±‚çš„å‚æ•°ï¼Œå®ƒä¸æ˜¯å¯è®­ç»ƒçš„ã€‚
        self.padding = kernel_size // 2
        self.weight_gain = 1 / np.sqrt(
            in_channels * (kernel_size ** 2))  # ç”¨æ¥è°ƒèŠ‚å·ç§¯æƒé‡çš„ç¼©æ”¾å› å­ï¼Œ1/sqrt(in_channels * kernel_size^2)ï¼Œè¿™æ˜¯ä¸ºäº†ä¿æŒè®­ç»ƒè¿‡ç¨‹ä¸­æ•°å€¼çš„ç¨³å®šæ€§
        self.act_gain = bias_act.activation_funcs[
            activation].def_gain  # æ¿€æ´»å‡½æ•°çš„å¢ç›Šï¼ˆé»˜è®¤çš„ gainï¼‰ï¼Œæ ¹æ®ä¸åŒæ¿€æ´»å‡½æ•°ç±»å‹ï¼ˆå¦‚ reluã€lreluï¼‰æ¥è°ƒæ•´è¾“å‡ºå¹…åº¦

        memory_format = torch.channels_last if channels_last else torch.contiguous_format
        weight = torch.randn([out_channels, in_channels, kernel_size, kernel_size]).to(memory_format=memory_format)
        bias = torch.zeros([out_channels]) if bias else None
        if trainable:  # åˆå§‹åŒ–å·ç§¯æ ¸æƒé‡å’Œåç½®é¡¹ã€‚æ ¹æ® trainable æ ‡å¿—å†³å®šè¿™äº›å‚æ•°æ˜¯å¦æ˜¯å¯å­¦ä¹ çš„ã€‚å¦‚æœä¸å¯è®­ç»ƒï¼Œåˆ™å°†å®ƒä»¬æ³¨å†Œä¸º bufferï¼ˆå›ºå®šå‚æ•°
            self.weight = torch.nn.Parameter(weight)
            self.bias = torch.nn.Parameter(bias) if bias is not None else None
        else:
            self.register_buffer('weight', weight)
            if bias is not None:
                self.register_buffer('bias', bias)
            else:
                self.bias = None

    def forward(self, x, gain=1):  # xï¼šè¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶é€šå¸¸ä¸º [batch_size, in_channels, height, width]ï¼›gainï¼šå¯é€‰çš„å¢ç›Šå› å­ï¼Œé»˜è®¤ä¸º 1ï¼Œç”¨äºæ§åˆ¶è¾“å‡ºçš„å¹…åº¦
        w = self.weight * self.weight_gain  # w = self.weight * self.weight_gainï¼šå¯¹å·ç§¯æ ¸çš„æƒé‡è¿›è¡Œç¼©æ”¾ï¼Œä»¥ä¿æŒæ•°å€¼çš„ç¨³å®šæ€§
        b = self.bias.to(x.dtype) if self.bias is not None else None
        flip_weight = (self.up == 1)  # slightly fasterè®¾ç½®ä¸º True æ—¶ä½¿ç”¨ç›¸å…³æ€§ä»£æ›¿å·ç§¯ï¼Œä»¥æé«˜é€Ÿåº¦
        x = conv2d_resample.conv2d_resample(x=x, w=w.to(x.dtype), f=self.resample_filter, up=self.up, down=self.down,
                                            padding=self.padding, flip_weight=flip_weight)
        # å¦‚æœ up > 1ï¼Œåˆ™åœ¨å·ç§¯ä¹‹å‰å¯¹è¾“å…¥è¿›è¡Œä¸Šé‡‡æ ·ï¼›å¦‚æœ down > 1ï¼Œåˆ™åœ¨å·ç§¯ä¹‹åå¯¹è¾“å‡ºè¿›è¡Œä¸‹é‡‡æ ·
        act_gain = self.act_gain * gain
        act_clamp = self.conv_clamp * gain if self.conv_clamp is not None else None
        x = bias_act.bias_act(x, b, act=self.activation, gain=act_gain, clamp=act_clamp)
        return x


# gain å’Œ clampï¼šé€šè¿‡ act_gain æ§åˆ¶æ¿€æ´»çš„å¢ç›Šï¼ŒåŒæ—¶å¯ä»¥é€‰æ‹©æ€§åœ°å¯¹è¾“å‡ºè¿›è¡Œè£å‰ªï¼ˆclamp
# å¯¹å·ç§¯ç»“æœåº”ç”¨åç½®å’Œæ¿€æ´»å‡½æ•°ã€‚å¦‚æœæä¾›äº†åç½® bï¼Œåˆ™åœ¨æ¿€æ´»å‡½æ•°ä¹‹å‰æ·»åŠ åç½®ã€‚æ¿€æ´»å‡½æ•°ç±»å‹å–å†³äº self.activationï¼Œå¦‚ ReLUã€LeakyReLU ç­‰
# ----------------------------------------------------------------------------

@persistence.persistent_class
# åœ¨è¾“å…¥ç‰¹å¾ä¸Šè¿›è¡Œå·ç§¯æ“ä½œï¼Œå¹¶åˆ©ç”¨ä½é¢‘å’Œé«˜é¢‘ä¿¡æ¯æ¥å¢å¼ºç½‘ç»œçš„è¡¨ç¤ºèƒ½åŠ›
class FFCBlock(torch.nn.Module):
    def __init__(self,
                 dim,  # Number of output/input channels.dim ä»£è¡¨è¾“å…¥ç‰¹å¾å›¾å’Œè¾“å‡ºç‰¹å¾å›¾çš„é€šé“æ•°ç›¸åŒ
                 kernel_size,  # Width and height of the convolution kernel.å·ç§¯æ ¸çš„å¤§å°
                 padding,  # å·ç§¯æ“ä½œä¸­ä½¿ç”¨çš„ padding å¤§å°ï¼Œç”¨äºæ§åˆ¶è¾“å‡ºç‰¹å¾å›¾çš„å°ºå¯¸
                 ratio_gin=0.75,  # å†³å®šè¾“å…¥å’Œè¾“å‡ºçš„å…¨å±€ï¼ˆé«˜é¢‘ï¼‰ç‰¹å¾çš„æ¯”ä¾‹
                 ratio_gout=0.75,
                 activation='linear',  # Activation function: 'relu', 'lrelu', etc.
                 ):
        super().__init__()
        if activation == 'linear':  # æ¿€æ´»å‡½æ•°ä¸º nn.Identityï¼ˆå³ä¸ä½¿ç”¨æ¿€æ´»
            self.activation = nn.Identity
        else:
            self.activation = nn.ReLU
        self.padding = padding
        self.kernel_size = kernel_size
        self.ffc_block = FFCResnetBlock(dim=dim,  # ç”¨äºå¯¹è¾“å…¥ç‰¹å¾å›¾è¿›è¡Œé¢‘ç‡åˆ†è§£å·ç§¯æ“ä½œã€‚FFCResnetBlock åœ¨åº•å±‚æ‰§è¡Œäº†ä¸¤æ¬¡å¸¦æœ‰æ®‹å·®è¿æ¥çš„å·ç§¯æ“ä½œ
                                        padding_type='reflect',  # è¡¨ç¤ºå·ç§¯æ—¶ä½¿ç”¨åå°„å¡«å……
                                        norm_layer=nn.SyncBatchNorm,  # æŒ‡å®šä½¿ç”¨åŒæ­¥æ‰¹é‡å½’ä¸€åŒ–å±‚
                                        activation_layer=self.activation,  # åœ¨å·ç§¯æ“ä½œåä½¿ç”¨çš„æ¿€æ´»å‡½æ•°
                                        dilation=1,
                                        ratio_gin=ratio_gin,  # æ§åˆ¶è¾“å…¥å’Œè¾“å‡ºçš„ä½é¢‘ä¸é«˜é¢‘é€šé“çš„æ¯”ä¾‹ã€‚
                                        ratio_gout=ratio_gout)

        self.concat_layer = ConcatTupleLayer()  # å°† FFC æ¨¡å—ç”Ÿæˆçš„ä½é¢‘å’Œé«˜é¢‘ç‰¹å¾å›¾æ‹¼æ¥åœ¨ä¸€èµ·

    def forward(self, gen_ft, mask, fname=None):
        x = gen_ft.float()  # è¾“å…¥çš„ç‰¹å¾å›¾ï¼Œå½¢çŠ¶ä¸º [batch_size, channels, height, width]ï¼Œå°†è¾“å…¥ gen_ft è½¬æ¢ä¸ºæµ®ç‚¹å‹æ•°æ®
        # è®¡ç®—å…¨å±€ï¼ˆé«˜é¢‘ï¼‰é€šé“æ•°é‡ï¼Œå¹¶å°† gen_ft åˆ†è§£ä¸ºå±€éƒ¨ï¼ˆä½é¢‘ï¼‰ç‰¹å¾å›¾ x_l å’Œå…¨å±€ï¼ˆé«˜é¢‘ï¼‰ç‰¹å¾å›¾ x_gï¼›x_g æ˜¯æœ€å global_in_num ä¸ªé€šé“ï¼Œè¡¨ç¤ºå…¨å±€ç‰¹å¾
        x_l, x_g = x[:, :-self.ffc_block.conv1.ffc.global_in_num], x[:, -self.ffc_block.conv1.ffc.global_in_num:]
        id_l, id_g = x_l, x_g  # x_lä»£è¡¨å‰ dim - global_in_num ä¸ªé€šé“ï¼Œè¡¨ç¤ºå±€éƒ¨ç‰¹å¾ï¼›
        # å°†åˆ†è§£å‡ºçš„å±€éƒ¨å’Œå…¨å±€ç‰¹å¾è¾“å…¥ffc_blockï¼Œè¿›è¡Œä¸¤æ¬¡é¢‘ç‡åˆ†è§£å·ç§¯æ“ä½œï¼Œåœ¨æ¯æ¬¡å·ç§¯æ“ä½œåï¼Œå°†è¾“å‡ºçš„å±€éƒ¨ç‰¹å¾ä¸è¾“å…¥çš„å±€éƒ¨ç‰¹å¾ç›¸åŠ ï¼Œè¾“å‡ºçš„å…¨å±€ç‰¹å¾ä¸è¾“å…¥çš„å…¨å±€ç‰¹å¾ç›¸åŠ ï¼ˆæ®‹å·®è¿æ¥
        x_l, x_g = self.ffc_block((x_l, x_g), fname=fname)
        x_l, x_g = id_l + x_l, id_g + x_g
        x = self.concat_layer((x_l, x_g))  # ä½¿ç”¨ self.concat_layer å°†å·ç§¯å¾—åˆ°çš„å±€éƒ¨ç‰¹å¾ x_l å’Œå…¨å±€ç‰¹å¾ x_g é‡æ–°æ‹¼æ¥åœ¨ä¸€èµ·ï¼Œå½¢æˆæ–°çš„ç‰¹å¾å›¾
        # å°†æ‹¼æ¥åçš„è¾“å‡ºç‰¹å¾ä¸æœ€åˆçš„è¾“å…¥ç‰¹å¾ gen_ft ç›¸åŠ ï¼ˆæ®‹å·®è¿æ¥ï¼‰ï¼Œä»è€Œå¾—åˆ°æœ€ç»ˆçš„è¾“å‡º
        return x + gen_ft.float()


# ----------------------------------------------------------------------------

@persistence.persistent_class
# ç”¨äºç¼–ç ç½‘ç»œæœ«ç«¯çš„æ¨¡å—ã€‚å®ƒå¯èƒ½è¿˜ä¼šåº”ç”¨æ¡ä»¶æ˜ å°„ã€‚ç”¨äºå°†è¾“å…¥ç‰¹å¾å›¾é€šè¿‡å·ç§¯ã€å…¨è¿æ¥ã€æ¡ä»¶æ˜ å°„ç­‰æ“ä½œï¼Œç”Ÿæˆæ½œåœ¨å‘é‡ zã€‚å®ƒåŒ…å«æ¡ä»¶å¤„ç†ã€MiniBatch æ ‡å‡†å·®ã€å·ç§¯ç­‰åŠŸèƒ½
class EncoderEpilogue(torch.nn.Module):
    def __init__(self,
                 in_channels,  # Number of input channels.
                 cmap_dim,  # Dimensionality of mapped conditioning label, æ¡ä»¶æ˜ å°„å‘é‡çš„ç»´åº¦ï¼Œ0 = no label.ç”¨äºæ¡ä»¶ç”Ÿæˆæˆ–æ¡ä»¶ç¼–ç 
                 z_dim,  # Output Latent (Z) dimensionality.æœ€ç»ˆè¾“å‡ºçš„æ½œåœ¨å‘é‡çš„å¤§å°
                 resolution,  # Resolution of this block.åˆ†è¾¨ç‡
                 img_channels,  # Number of input color channels.
                 architecture='resnet',  # Architecture: 'origåŸå§‹æ¶æ„', 'skip', 'resnet'.
                 mbstd_group_size=4,
                 # Group size for the minibatch standard deviation layer, None = entire minibatchï¼ˆmini-batchï¼‰.MiniBatchæ ‡å‡†å·®å±‚çš„ç»„å¤§å°
                 mbstd_num_channels=1,
                 # Number of features for the minibatch standard deviation layer, 0 = disable.MiniBatch æ ‡å‡†å·®å±‚çš„é€šé“æ•°
                 activation='lrelu',  # Activation function: 'relu', 'lrelu', etc.
                 conv_clamp=None,
                 # Clamp the output of convolution layers to +-X, None = disable clamping.å·ç§¯å±‚è¾“å‡ºçš„å¤¹ç´§å€¼, None=ç¦ç”¨å¤¹ç´§
                 ):
        assert architecture in ['orig', 'skip', 'resnet']
        super().__init__()
        self.in_channels = in_channels
        self.cmap_dim = cmap_dim
        self.resolution = resolution
        self.img_channels = img_channels
        self.architecture = architecture

        if architecture == 'skip':
            self.fromrgb = Conv2dLayer(self.img_channels, in_channels, kernel_size=1, activation=activation)

        self.mbstd = MinibatchStdLayer(group_size=mbstd_group_size,
                                       num_channels=mbstd_num_channels) if mbstd_num_channels > 0 else None
        # æ ¸å¿ƒå·ç§¯å±‚ã€‚è¾“å…¥é€šé“æ•°ä¸º in_channels + mbstd_num_channelsï¼ˆå› ä¸ºå¯èƒ½åŠ å…¥ MiniBatch æ ‡å‡†å·®é€šé“ï¼‰ï¼Œç„¶åå†è¾“å‡ºç›¸åŒçš„ in_channels
        self.conv = Conv2dLayer(in_channels + mbstd_num_channels, in_channels, kernel_size=3, activation=activation,
                                conv_clamp=conv_clamp)
        # å…¨è¿æ¥å±‚ï¼Œç”¨äºå°†å·ç§¯ç‰¹å¾è½¬åŒ–ä¸ºæ½œåœ¨ç©ºé—´çš„å‘é‡ zï¼Œå¹¶åº”ç”¨äº† Dropoutï¼Œé¿å…è¿‡æ‹Ÿåˆ
        self.fc = FullyConnectedLayer(in_channels * (resolution ** 2), z_dim, activation=activation)
        self.dropout = torch.nn.Dropout(p=0.5)

    def forward(self, x, cmap, force_fp32=False):  # x: è¾“å…¥ç‰¹å¾å›¾ï¼Œå½¢çŠ¶ä¸º[batch_size, in_chann, reso, reso]ï¼Œæ¡ä»¶æ˜ å°„å‘é‡ï¼ˆç”¨äºæ¡ä»¶ç”Ÿæˆï¼‰ï¼Œå½¢çŠ¶ä¸º [batch_size, cmap_dim]
        misc.assert_shape(x, [None, self.in_channels, self.resolution, self.resolution])  # [NCHW]
        _ = force_fp32  # unused
        dtype = torch.float32
        memory_format = torch.contiguous_format

        # FromRGB.å°†è¾“å…¥ x è½¬æ¢ä¸ºæŒ‡å®šçš„æ•°æ®ç±»å‹å’Œå†…å­˜æ ¼å¼ï¼Œ
        x = x.to(dtype=dtype, memory_format=memory_format)

        # Main layers.å¦‚æœå¯ç”¨äº† MiniBatch æ ‡å‡†å·®å±‚ï¼Œè®¡ç®—å¹¶åŠ å…¥æ ‡å‡†å·®ç‰¹å¾
        if self.mbstd is not None:
            x = self.mbstd(x)
        const_e = self.conv(x)  # é€šè¿‡å·ç§¯å±‚æå–ç‰¹å¾ const_eï¼Œç„¶åå°†å…¶å±•å¹³å¹¶è¾“å…¥å…¨è¿æ¥å±‚ç”Ÿæˆæ½œåœ¨å‘é‡ zï¼Œä¹‹ååº”ç”¨ Dropout
        x = self.fc(const_e.flatten(1))
        x = self.dropout(x)

        # Conditioning.å°†æ½œåœ¨å‘é‡ x ä¸æ¡ä»¶å‘é‡ cmap è¿›è¡Œé€å…ƒç´ ç›¸ä¹˜ï¼Œéšåæ²¿ dim=1 ç»´åº¦æ±‚å’Œï¼Œå¹¶åšå½’ä¸€åŒ–ã€‚
        if self.cmap_dim > 0:
            misc.assert_shape(cmap, [None, self.cmap_dim])
            x = (x * cmap).sum(dim=1, keepdim=True) * (1 / np.sqrt(self.cmap_dim))

        assert x.dtype == dtype
        return x, const_e  # x: æœ€ç»ˆçš„æ½œåœ¨å‘é‡ï¼ˆå¯èƒ½ç»è¿‡æ¡ä»¶æ˜ å°„ï¼‰ã€‚const_e: é€šè¿‡å·ç§¯å±‚æå–çš„ç‰¹å¾å›¾


# ----------------------------------------------------------------------------

from training.Gsop import GSoP
@persistence.persistent_class
class EncoderBlock(torch.nn.Module):  # ç”¨äºå¤„ç†è¾“å…¥å›¾åƒæˆ–ç‰¹å¾å›¾å¹¶ç”Ÿæˆç‰¹å¾è¡¨ç¤º
    def __init__(self,
                 in_channels,  # Number of input channels, 0 = first block.
                 tmp_channels,  # Number of intermediate channels. ä¸­é—´ç‰¹å¾çš„é€šé“æ•°.
                 out_channels,  # Number of output channels.
                 resolution,  # Resolution of this block.
                 img_channels,  # Number of input color channels.è¾“å…¥å›¾åƒçš„é¢œè‰²é€šé“æ•°
                 first_layer_idx,  # Index of the first layer.
                 architecture='skip',  # Architecture: 'orig', 'skip', 'resnet'.
                 activation='lrelu',  # Activation function: 'relu', 'lrelu', etc.
                 resample_filter=[1, 3, 3, 1],  # Low-pass filter to apply when resampling activations.ä½é€šæ»¤æ³¢å™¨ç”¨äºä¸Š/ä¸‹é‡‡æ ·
                 conv_clamp=None,  # Clamp the output of convolution layers to +-X, None = disable clamping.å·ç§¯å±‚è¾“å‡ºå€¼çš„å¤¹ç´§
                 use_fp16=False,  # Use FP16 for this block?æ˜¯å¦ä½¿ç”¨ FP16 è®¡ç®—ç²¾åº¦
                 fp16_channels_last=False,
                 # Use channels-last memory format with FP16?æ˜¯å¦åœ¨ FP16 ä¸‹ä½¿ç”¨ `channels_last` å†…å­˜æ ¼å¼
                 freeze_layers=0,  # Freeze-D: Number of layers to freeze.å†»ç»“å‰å¤šå°‘å±‚ï¼ˆå³è¿™äº›å±‚ä¸å‚ä¸è®­ç»ƒï¼‰
                 num_heads=8,  # 2++++æ–°å¢å‚æ•°ï¼šæ³¨æ„åŠ›å¤´æ•°
                 bias=True  # 2+++++æ–°å¢å‚æ•°ï¼šæ³¨æ„åŠ›å±‚ä¸­çš„ bias è®¾ç½®
                 ):
        # æ–­è¨€è¯­å¥ï¼Œç”¨äºåœ¨ä»£ç æ‰§è¡Œæ—¶æ£€æŸ¥æŸäº›æ¡ä»¶æ˜¯å¦æ»¡è¶³
        assert in_channels in [0, tmp_channels]
        assert architecture in ['orig', 'skip', 'resnet']
        super().__init__()  # è°ƒç”¨äº†çˆ¶ç±» torch.nn.Module çš„æ„é€ å‡½æ•°ã€‚
        # è®¾ç½®ç±»å±æ€§
        self.in_channels = in_channels
        self.resolution = resolution  # å®ƒæŒ‡çš„æ˜¯ç‰¹å¾å›¾çš„é«˜åº¦å’Œå®½åº¦ã€‚
        self.img_channels = img_channels + 1
        self.first_layer_idx = first_layer_idx
        self.architecture = architecture  # ä¿å­˜ç¬¬ä¸€ä¸ªå±‚çš„ç´¢å¼•ã€‚è¯¥ç´¢å¼•å¯ä»¥ç”¨äºç¡®å®šå½“å‰å±‚åœ¨æ•´ä¸ªç½‘ç»œä¸­çš„ä½ç½®ã€‚
        self.use_fp16 = use_fp16
        self.channels_last = (use_fp16 and fp16_channels_last)
        self.register_buffer('resample_filter', upfirdn2d.setup_filter(resample_filter))
        # register_buffer æ³¨å†Œäº†ä¸€ä¸ªç§°ä¸º resample_filter çš„å¸¸é‡ï¼ˆå³ä¸ä¼šå‚ä¸æ¨¡å‹çš„å‚æ•°æ›´æ–°
        self.num_layers = 0  # ç”¨äºè®°å½•å½“å‰ block ä¸­çš„å±‚æ•°

        def trainable_gen():  # ç”Ÿæˆå™¨å‡½æ•°ï¼Œç”¨äºç¡®å®šæ¯ä¸€å±‚æ˜¯å¦æ˜¯å¯è®­ç»ƒçš„
            while True:
                layer_idx = self.first_layer_idx + self.num_layers
                trainable = (layer_idx >= freeze_layers)
                self.num_layers += 1
                yield trainable

        trainable_iter = trainable_gen()

        if in_channels == 0:  # å¦‚æœè¾“å…¥æ˜¯å›¾åƒè€Œä¸æ˜¯ç‰¹å¾å›¾ï¼Œå®šä¹‰ä¸€ä¸ª 1x1 çš„å·ç§¯å±‚ç”¨äºä» RGB å›¾åƒä¸­æå–ç‰¹å¾ï¼Œå¹¶å°† img_channels è½¬æ¢ä¸º tmp_channels
            self.fromrgb = Conv2dLayer(self.img_channels, tmp_channels, kernel_size=1, activation=activation,
                                       trainable=next(trainable_iter), conv_clamp=conv_clamp,
                                       channels_last=self.channels_last)
        # conv0 å’Œ conv1 æ˜¯æ ¸å¿ƒçš„å·ç§¯æ“ä½œï¼Œconv1 åœ¨å·ç§¯åè¿›è¡Œä¸‹é‡‡æ ·ï¼ˆdown=2ï¼‰ï¼Œå³å°†åˆ†è¾¨ç‡å‡å°‘ä¸€åŠ
        self.conv0 = Conv2dLayer(tmp_channels, tmp_channels, kernel_size=3, activation=activation,
                                 trainable=next(trainable_iter), conv_clamp=conv_clamp,
                                 channels_last=self.channels_last)

        self.conv1 = Conv2dLayer(tmp_channels, out_channels, kernel_size=3, activation=activation, down=2,
                                 trainable=next(trainable_iter), resample_filter=resample_filter, conv_clamp=conv_clamp,
                                 channels_last=self.channels_last)

        if architecture == 'resnet':  # 0
            self.skip = Conv2dLayer(tmp_channels, out_channels, kernel_size=1, bias=False, down=2,
                                    trainable=next(trainable_iter), resample_filter=resample_filter,
                                    channels_last=self.channels_last)
        # self.gsop = GSoP.GSoP(out_channels, attention='+', att_dim=128)   # 4++++ gsop

    def forward(self, x, img, force_fp32=False):
        dtype = torch.float16 if self.use_fp16 and not force_fp32 else torch.float32
        memory_format = torch.channels_last if self.channels_last and not force_fp32 else torch.contiguous_format

        # Input.
        if x is not None:  # æ£€æŸ¥è¾“å…¥çš„å½¢çŠ¶æ˜¯å¦ç¬¦åˆé¢„æœŸï¼Œç¡®ä¿å…¶æ˜¯ [batch_size, in_channels, resolution, resolution] çš„æ ¼å¼
            misc.assert_shape(x, [None, self.in_channels, self.resolution, self.resolution])
            x = x.to(dtype=dtype, memory_format=memory_format)

        # FromRGB.
        if self.in_channels == 0:  # è¿™æ˜¯ç½‘ç»œçš„ç¬¬ä¸€ä¸ª blockï¼ˆå³ in_channels == 0ï¼‰ï¼Œåˆ™ä» RGB å›¾åƒä¸­æå–ç‰¹å¾
            misc.assert_shape(img, [None, self.img_channels, self.resolution, self.resolution])
            img = img.to(dtype=dtype, memory_format=memory_format)
            y = self.fromrgb(img)
            x = x + y if x is not None else y
            img = upfirdn2d.downsample2d(img, self.resample_filter) if self.architecture == 'skip' else None
        # å¦‚æœæ¶æ„æ˜¯ skipï¼Œå¯¹å›¾åƒè¿›è¡Œä¸‹é‡‡æ ·ä»¥ä¿æŒåˆ†è¾¨ç‡ä¸€è‡´æ€§
        # Main layers.
        if self.architecture == 'resnet':  # 0
            y = self.skip(x, gain=np.sqrt(0.5))
            x = self.conv0(x)  # ä¹‹åï¼Œç»è¿‡ conv0 è¿›è¡Œå·ç§¯å¹¶ä¿å­˜ä¸­é—´ç‰¹å¾ featï¼Œç„¶åé€šè¿‡ conv1 è¿›è¡Œä¸‹é‡‡æ ·

            feat = x.clone()
            x = self.conv1(x, gain=np.sqrt(0.5))
            x = y.add_(x)  # å°†è·³è·ƒè¿æ¥çš„ç»“æœ y å’Œ conv1 çš„è¾“å‡º x ç›¸åŠ ï¼Œå¾—åˆ°æœ€ç»ˆçš„ç‰¹å¾
        else:  # ç®€å•åœ°é€šè¿‡ conv0 å’Œ conv1 è¿›è¡Œå·ç§¯å’Œä¸‹é‡‡æ ·ï¼Œå¹¶ä¸”ä¿å­˜ä¸­é—´ç‰¹å¾ featã€‚  #  111
            x = self.conv0(x)
            feat = x.clone()
            x = self.conv1(x)

            # x = self.gsop(x)  # 4++++

        # x = x.to(dtype)  # 4++++
        assert x.dtype == dtype

        return x, img, feat


# xï¼šå½“å‰ block çš„è¾“å‡ºç‰¹å¾å›¾ï¼ˆå¯èƒ½æ˜¯ä¸‹ä¸€ä¸ª block çš„è¾“å…¥ï¼›imgï¼šä¸‹é‡‡æ ·åçš„å›¾åƒï¼ˆåœ¨ skip æ¶æ„ä¸­ï¼›featï¼šå½“å‰ block ä¸­çš„ä¸­é—´ç‰¹å¾ï¼Œç”¨äºåœ¨è¿›ä¸€æ­¥çš„å±‚ä¸­è¿›è¡Œè®¡ç®—
# ----------------------------------------------------------------------------

@persistence.persistent_class
class SynthesisLayer(torch.nn.Module):
    def __init__(self,
                 in_channels,  # Number of input channels.
                 out_channels,  # Number of output channels.
                 w_dim,  # Intermediate latent (W) dimensionality.ç”¨äºé£æ ¼åŒ–æ“ä½œçš„æ½œåœ¨å‘é‡ w çš„ç»´åº¦
                 resolution,  # Resolution of this layer.å†³å®šè¾“å‡ºå›¾åƒæˆ–ç‰¹å¾å›¾çš„å¤§å°
                 kernel_size=3,  # Convolution kernel size.
                 up=1,  # Integer upsampling factor.1ï¼Œè¡¨ç¤ºæ²¡æœ‰ä¸Šé‡‡æ ·
                 use_noise=True,  # Enable noise input?åœ¨ç”Ÿæˆç½‘ç»œä¸­å¯ä»¥å¼•å…¥éšæœºæ€§
                 activation='lrelu',  # Activation function: 'relu', 'lrelu', etc.
                 resample_filter=[1, 3, 3, 1],  # Low-pass filter to apply when resampling activations.
                 conv_clamp=None,
                 # Clamp the output of convolution layers to +-X, None = disable clamping.ç”¨äºæ§åˆ¶å·ç§¯å±‚è¾“å‡ºçš„æœ€å¤§å€¼ï¼Œé¿å…æ•°å€¼è¿‡å¤§ã€‚
                 channels_last=False,  # Use channels_last format for the weights?
                 ):
        super().__init__()
        self.resolution = resolution
        self.up = up
        self.use_noise = use_noise
        self.activation = activation
        self.conv_clamp = conv_clamp
        self.register_buffer('resample_filter', upfirdn2d.setup_filter(resample_filter))
        self.padding = kernel_size // 2
        self.act_gain = bias_act.activation_funcs[activation].def_gain

        self.affine = FullyConnectedLayer(w_dim, in_channels, bias_init=1)  # å…¨è¿æ¥å±‚ï¼Œè´Ÿè´£å°†é£æ ¼å‘é‡ w æŠ•å½±ä¸ºè¾“å…¥é€šé“çš„ç¼©æ”¾å› å­ï¼ˆç”¨äºè°ƒåˆ¶å·ç§¯æ ¸
        memory_format = torch.channels_last if channels_last else torch.contiguous_format
        self.weight = torch.nn.Parameter(torch.randn([out_channels, in_channels, kernel_size, kernel_size]).to(
            memory_format=memory_format))  # å·ç§¯æ ¸æƒé‡ï¼Œéšæœºåˆå§‹åŒ–
        if use_noise:  # å¯ç”¨äº†å™ªå£°æ³¨å…¥ï¼Œnoise_const æ˜¯ç”¨äºç”Ÿæˆå›ºå®šå™ªå£°çš„å¸¸é‡ï¼Œè€Œ noise_strength æ§åˆ¶å™ªå£°çš„å¼ºåº¦
            self.register_buffer('noise_const', torch.randn([resolution, resolution]))
            self.noise_strength = torch.nn.Parameter(torch.zeros([]))
        self.bias = torch.nn.Parameter(torch.zeros([out_channels]))  # å·ç§¯æ“ä½œåçš„åç½®é‡

    # x: è¾“å…¥ç‰¹å¾å›¾ï¼Œå½¢çŠ¶ä¸º [batch_size, in_channels, height, width]ï¼›é£æ ¼å‘é‡ wï¼Œç”¨äºè°ƒèŠ‚å·ç§¯æ ¸æƒé‡ï¼›æ§åˆ¶æ˜¯å¦æ·»åŠ å™ªå£°åŠå¦‚ä½•æ·»åŠ ã€‚å¯é€‰å€¼åŒ…æ‹¬ 'random'ï¼ˆéšæœºå™ªå£°ï¼‰ã€'const'ï¼ˆå›ºå®šå™ªå£°ï¼‰å’Œ 'none'ï¼ˆæ— å™ªå£°ï¼‰
    # fused_modconv: æ˜¯å¦å°†è°ƒåˆ¶å·ç§¯æ“ä½œä¸å·ç§¯æ“ä½œèåˆï¼Œæå‡è®¡ç®—æ•ˆç‡ï¼›gain: æ§åˆ¶æ¿€æ´»è¾“å‡ºçš„ç¼©æ”¾å› å­
    def forward(self, x, w, noise_mode='random', fused_modconv=True, gain=1):
        assert noise_mode in ['random', 'const', 'none']
        in_resolution = self.resolution // self.up
        misc.assert_shape(x, [None, self.weight.shape[1], in_resolution, in_resolution])  # ç¡®ä¿è¾“å…¥çš„ç‰¹å¾å›¾å½¢çŠ¶åŒ¹é…æœŸæœ›çš„å·ç§¯è¾“å…¥å½¢çŠ¶
        styles = self.affine(w)  # ä½¿ç”¨å…¨è¿æ¥å±‚ affine å°†é£æ ¼å‘é‡ ğ‘¤è½¬æ¢ä¸ºå·ç§¯æ ¸çš„è°ƒåˆ¶å› å­ stylesã€‚è¿™äº›å› å­ç”¨äºè°ƒèŠ‚å·ç§¯æ ¸æƒé‡

        noise = None  # ç”Ÿæˆéšæœºå™ªå£°ï¼Œå¹¶æŒ‰ noise_strength çš„æ¯”ä¾‹ç¼©æ”¾ã€‚å¦‚æœæ˜¯ 'const'ï¼Œåˆ™ä½¿ç”¨é¢„å®šä¹‰çš„å™ªå£°å¸¸é‡ noise_const
        if self.use_noise and noise_mode == 'random':
            noise = torch.randn([x.shape[0], 1, self.resolution, self.resolution],
                                device=x.device) * self.noise_strength
        if self.use_noise and noise_mode == 'const':
            noise = self.noise_const * self.noise_strength

        flip_weight = (self.up == 1)  # slightly faster
        # è°ƒç”¨ modulated_conv2d å‡½æ•°æ‰§è¡Œè°ƒåˆ¶å·ç§¯x æ˜¯è¾“å…¥ç‰¹å¾å›¾ã€‚weight æ˜¯å·ç§¯æ ¸çš„æƒé‡ï¼Œç”±é£æ ¼å› å­ styles è°ƒåˆ¶ã€‚noise æ˜¯å™ªå£°ï¼ˆå¦‚æœå¯ç”¨ï¼‰ã€‚up æ˜¯ä¸Šé‡‡æ ·å› å­ï¼ˆå†³å®šæ˜¯å¦ä¸Šé‡‡æ ·ï¼‰ã€‚
        # padding ç”¨äºä¿æŒå·ç§¯åè¾“å‡ºçš„å°ºå¯¸ã€‚resample_filter ç”¨äºå¯¹å·ç§¯ç»“æœè¿›è¡Œä½é€šæ»¤æ³¢ï¼Œç¡®ä¿å¹³æ»‘ã€‚flip_weight æ˜¯å·ç§¯æ ¸çš„ç¿»è½¬æ ‡å¿—ï¼Œç”¨äºåŠ é€Ÿè®¡ç®—
        x = modulated_conv2d(x=x, weight=self.weight, styles=styles, noise=noise, up=self.up,
                             padding=self.padding, resample_filter=self.resample_filter, flip_weight=flip_weight,
                             fused_modconv=fused_modconv)

        act_gain = self.act_gain * gain
        act_clamp = self.conv_clamp * gain if self.conv_clamp is not None else None  # å¦‚æœæœ‰ conv_clampï¼Œåˆ™é€šè¿‡ clamp å°†è¾“å‡ºé™åˆ¶åœ¨ç‰¹å®šèŒƒå›´å†…ï¼Œé¿å…æ•°å€¼æº¢å‡º
        x = F.leaky_relu(x, negative_slope=0.2, inplace=False)  # ä½¿ç”¨ Leaky ReLU ä½œä¸ºæ¿€æ´»å‡½æ•°ï¼ˆé»˜è®¤æƒ…å†µä¸‹ï¼Œnegative_slope=0.2ï¼‰
        if act_gain != 1:
            x = x * act_gain  # act_gain æ§åˆ¶æ¿€æ´»åçš„è¾“å‡ºç¼©æ”¾
        if act_clamp is not None:
            x = x.clamp(-act_clamp, act_clamp)
        return x


# è¯¥å±‚åœ¨å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­èƒ½å¤Ÿå°†æ½œåœ¨ç©ºé—´ä¸­çš„é£æ ¼å‘é‡ ğ‘¤é€šè¿‡è°ƒåˆ¶å·ç§¯æ˜ å°„ä¸ºå›¾åƒç‰¹å¾ã€‚å®ƒçš„è®¾è®¡å…è®¸ç”Ÿæˆå…·æœ‰ä¸åŒé£æ ¼å’Œç»†èŠ‚çš„é«˜åˆ†è¾¨ç‡å›¾åƒã€‚
# ----------------------------------------------------------------------------

@persistence.persistent_class
# é€šè¿‡ FFCBlock æ‰§è¡Œä¸€ä¸ªè·³è·ƒè¿æ¥å±‚ï¼ˆskip connectionï¼‰ã€‚å®ƒè¢«è®¾è®¡ä¸ºåœ¨è¾“å…¥å’Œè¾“å‡ºçš„ç‰¹å¾å›¾ä¹‹é—´æ‰§è¡Œç‰¹å®šçš„è¿ç®—ï¼Œä½¿ç‰¹å¾å›¾ä¿ç•™ä¸€äº›ä¿¡æ¯ï¼ŒåŒæ—¶åœ¨ä¸­é—´é€šè¿‡ FFCBlock è¿›è¡Œå¤„ç†ã€‚
# è¾“å…¥ç‰¹å¾å›¾ä¸­çš„ä¿¡æ¯ä¸ä¼šè¢«å®Œå…¨æŠ›å¼ƒï¼Œè€Œæ˜¯é€šè¿‡è·³è·ƒè¿æ¥çš„æ–¹å¼ä¿ç•™ï¼ŒåŒæ—¶å¼•å…¥äº†æ–°çš„ç»è¿‡å¤„ç†çš„ç‰¹å¾
class FFCSkipLayer(torch.nn.Module):
    def __init__(self,
                 dim,  # Number of input/output channels.é€šå¸¸ç‰¹å¾å›¾çš„æ·±åº¦ï¼ˆå³é€šé“æ•°ï¼‰æ˜¯è¾“å…¥å’Œè¾“å‡ºç›¸åŒçš„
                 kernel_size=3,  # Convolution kernel size.å†³å®šå·ç§¯æ“ä½œçš„æ„Ÿå—é‡å¤§å°
                 ratio_gin=0.75,  # åˆ†åˆ«æ§åˆ¶å…¨å±€å’Œå±€éƒ¨é€šé“çš„æ¯”ç‡ã€‚è¿™äº›å‚æ•°æ¥è‡ªäº FFCBlockï¼Œè¯¥æ¨¡å—å°†è¾“å…¥ç‰¹å¾åˆ†ä¸ºå…¨å±€å’Œå±€éƒ¨ç‰¹å¾å›¾ï¼Œåˆ†åˆ«å¤„ç†
                 ratio_gout=0.75,
                 ):
        super().__init__()
        self.padding = kernel_size // 2  # è®¡ç®—å‡ºå·ç§¯å±‚éœ€è¦çš„å¡«å……å¤§å°ã€‚è¿™ç¡®ä¿è¾“å…¥å’Œè¾“å‡ºçš„ç©ºé—´ç»´åº¦ä¿æŒä¸€è‡´ã€‚
        # å®ä¾‹åŒ–äº†ä¸€ä¸ª FFCBlockã€‚FFCBlock æ˜¯ä¸€ç§ä¸“é—¨ç”¨äºå¤„ç†å±€éƒ¨å’Œå…¨å±€ç‰¹å¾çš„æ¨¡å—ã€‚å®ƒå°†è¾“å…¥çš„ç‰¹å¾å›¾åˆ†ä¸ºå±€éƒ¨å’Œå…¨å±€ä¸¤éƒ¨åˆ†ï¼Œåˆ†åˆ«è¿›è¡Œå¤„ç†ï¼Œå†åˆå¹¶ã€‚padding: ä¿è¯è¾“å…¥è¾“å‡ºçš„å°ºå¯¸ä¸€è‡´
        self.ffc_act = FFCBlock(dim=dim, kernel_size=kernel_size, activation=nn.ReLU,
                                padding=self.padding, ratio_gin=ratio_gin, ratio_gout=ratio_gout)

    # gen_ft: è¾“å…¥çš„ç‰¹å¾å›¾ï¼Œå½¢çŠ¶ä¸º [batch_size, dim, height, width]ï¼Œè¡¨ç¤ºè¾“å…¥çš„ç‰¹å¾å¼ é‡ï¼›æ©ç ï¼Œç”¨äºå±€éƒ¨ç‰¹å¾å’Œå…¨å±€ç‰¹å¾çš„å¤„ç†ï¼›æ–‡ä»¶åå‚æ•°ï¼Œé€šå¸¸ç”¨äºè°ƒè¯•æˆ–è®°å½•è¿‡ç¨‹ä¸­ä¼ é€’çš„é™„åŠ ä¿¡æ¯
    def forward(self, gen_ft, mask, fname=None):
        # é€šè¿‡ FFCBlock å¯¹è¾“å…¥ç‰¹å¾å›¾ gen_ft è¿›è¡Œå¤„ç†ã€‚FFCBlock å†…éƒ¨ä¼šå°†è¾“å…¥ç‰¹å¾æ‹†åˆ†ä¸ºå±€éƒ¨å’Œå…¨å±€éƒ¨åˆ†ï¼Œåˆ†åˆ«è¿›è¡Œå·ç§¯ã€æ¿€æ´»ç­‰æ“ä½œï¼Œç„¶åå†åˆå¹¶è¿™äº›ç‰¹å¾
        # mask ä¹Ÿä¼šå½±å“ç‰¹å¾å›¾çš„å¤„ç†ï¼Œå¸®åŠ©æ§åˆ¶å“ªäº›åŒºåŸŸåº”è¯¥ç”¨å±€éƒ¨å·ç§¯ï¼Œå“ªäº›åº”è¯¥ç”¨å…¨å±€å·ç§¯ã€‚
        x = self.ffc_act(gen_ft, mask, fname=fname)
        return x  # è¿”å›å¤„ç†è¿‡çš„ç‰¹å¾å›¾ xï¼Œç›¸å½“äºæ‰§è¡Œäº†ä¸€ä¸ª "skip" æ“ä½œï¼Œå³åœ¨åŸå§‹è¾“å…¥ç‰¹å¾ä¸Šå åŠ äº†ä¸€äº›ç»è¿‡å¤„ç†çš„é¢å¤–ä¿¡æ¯ã€‚


# ----------------------------------------------------------------------------

@persistence.persistent_class
# å°†ç‰¹å¾æ˜ å°„è½¬æ¢ä¸º RGB å›¾åƒï¼Œå¸¸ç”¨äºç”Ÿæˆç½‘ç»œçš„æœ€åé˜¶æ®µã€‚å®ƒå°†é«˜ç»´çš„ç‰¹å¾å›¾è½¬æ¢æˆå®é™…çš„å›¾åƒï¼Œé€šè¿‡å·ç§¯å’Œç‰¹å¾è°ƒåˆ¶çš„æ–¹å¼ï¼Œè¾“å‡ºæœŸæœ›çš„é¢œè‰²é€šé“ï¼ˆé€šå¸¸æ˜¯RGBï¼Œè¾“å‡ºé€šé“æ•°ä¸º3
class ToRGBLayer(torch.nn.Module):
    # w_dim: è¾“å…¥çš„æ½œåœ¨å‘é‡ w çš„ç»´åº¦ã€‚é€šå¸¸è¿™æ˜¯ä¸€ä¸ªä¸­é—´è¡¨ç¤ºï¼Œæºè‡ªæ›´æ—©çš„æ½œåœ¨å‘é‡ z ç»è¿‡å¤šå±‚å˜æ¢å¾—åˆ°çš„ w
    def __init__(self, in_channels, out_channels, w_dim, kernel_size=1, conv_clamp=None, channels_last=False):
        super().__init__()
        self.conv_clamp = conv_clamp
        self.affine = FullyConnectedLayer(w_dim, in_channels,
                                          bias_init=1)  # å°†æ½œåœ¨å‘é‡wè½¬æ¢ä¸ºä¸è¾“å…¥ç‰¹å¾å›¾é€šé“æ•°åŒ¹é…çš„æ ·å¼å‘é‡styleã€‚wç»è¿‡affineå±‚åç”Ÿæˆä¸€ç»„è°ƒåˆ¶å‚æ•°ï¼Œæ¥æ§åˆ¶å·ç§¯æƒé‡ã€‚
        memory_format = torch.channels_last if channels_last else torch.contiguous_format  # ç¡®å®šæƒé‡çš„å­˜å‚¨æ ¼å¼ã€‚å¦‚æœchannels_laståˆ™ä½¿ç”¨channels_lasæ ¼å¼æ¥åŠ é€Ÿè®¡ç®—ã€‚å¦åˆ™ç”¨contiguousæ ¼å¼
        # å·ç§¯çš„æƒé‡çŸ©é˜µï¼Œå¤§å°ä¸º [out_channels, in_channels, kernel_size, kernel_size]ã€‚é€šè¿‡éšæœºåˆå§‹åŒ–ï¼Œéšåä¼šé€šè¿‡ w å‘é‡è°ƒåˆ¶è¿™äº›æƒé‡
        self.weight = torch.nn.Parameter(
            torch.randn([out_channels, in_channels, kernel_size, kernel_size]).to(memory_format=memory_format))
        self.bias = torch.nn.Parameter(torch.zeros([out_channels]))  # è¾“å‡ºç‰¹å¾çš„åç½®ï¼Œåˆå§‹åŒ–ä¸º 0ã€‚ç”¨äºè°ƒæ•´å·ç§¯çš„ç»“æœã€‚
        self.weight_gain = 1 / np.sqrt(in_channels * (kernel_size ** 2))  # æƒé‡å¢ç›Šå› å­ã€‚é€šè¿‡ç¼©æ”¾æƒé‡ï¼Œé¿å…å› è¾“å…¥é€šé“æ•°è¾ƒå¤§æ—¶å·ç§¯ç»“æœè¿‡å¤§ï¼Œç¨³å®šè®­ç»ƒè¿‡ç¨‹

    def forward(self, x, w, fused_modconv=True):
        # x: è¾“å…¥çš„ç‰¹å¾å›¾ï¼Œå½¢çŠ¶ä¸º [batch_size, in_channels, height, width]ï¼›w: æ½œåœ¨å‘é‡ wï¼Œç”¨äºç”Ÿæˆæ ·å¼å‘é‡ã€‚fused_modconv: å¦‚æœä¸º Trueï¼Œä½¿ç”¨èåˆçš„è°ƒåˆ¶å·ç§¯è¿›è¡Œé«˜æ•ˆè®¡ç®—ã€‚å¦åˆ™ä¼šåˆ†æ­¥æ‰§è¡Œè°ƒåˆ¶å’Œå·ç§¯
        styles = self.affine(
            w) * self.weight_gain  # é€šè¿‡affineå±‚å°†è¾“å…¥çš„æ½œåœ¨å‘é‡wè½¬æ¢ä¸ºè°ƒåˆ¶å‘é‡stylesã€‚è°ƒåˆ¶å‘é‡å¤§å°ä¸º[batch_size, in_channels]ï¼Œä¹˜ä»¥wei_gaï¼Œä»¥æ§åˆ¶æƒé‡çš„å¹…åº¦ï¼Œé˜²æ­¢æ•°å€¼è¿‡å¤§å¯¼è‡´æ¢¯åº¦çˆ†ç‚¸
        # å·ç§¯æ“ä½œï¼Œå·ç§¯æ ¸æƒé‡ä¼šè¢« styles å‘é‡è°ƒåˆ¶ï¼ˆå³é€ä¸ªå…ƒç´ åœ°ä¹˜ä»¥æ ·å¼å‘é‡ï¼‰ã€‚demodulate=False: è¿™é‡Œä¸æ‰§è¡Œåè°ƒåˆ¶æ“ä½œï¼›used_modconv: å¦‚æœä¸º Trueï¼Œåˆ™ä¼šå°†è°ƒåˆ¶å’Œå·ç§¯æ“ä½œèåˆä¸ºä¸€ä¸ªæ›´é«˜æ•ˆçš„æ“ä½œ
        x = modulated_conv2d(x=x, weight=self.weight, styles=styles, demodulate=False, fused_modconv=fused_modconv)
        # bias_act å‡½æ•°ä¼šå¯¹å·ç§¯çš„ç»“æœ x æ·»åŠ åç½®ï¼Œå¹¶åº”ç”¨æ¿€æ´»å‡½æ•°ã€‚åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œè¿˜å¯ä»¥é€‰æ‹©æ€§åœ°å¯¹è¾“å‡ºè¿›è¡Œè£å‰ªï¼ˆç”± conv_clamp æ§åˆ¶ï¼›self.bias.to(x.dtype)ï¼šå°†åç½®è½¬æ¢ä¸ºä¸è¾“å…¥ç‰¹å¾å›¾ç›¸åŒçš„æ•°æ®ç±»å‹ã€‚
        # clamp=self.conv_clampï¼šå¦‚æœ conv_clamp ä¸ä¸º Noneï¼Œåˆ™å¯¹è¾“å‡ºè¿›è¡Œè£å‰ªï¼Œç¡®ä¿å…¶åœ¨æŒ‡å®šèŒƒå›´å†…ã€‚
        x = bias_act.bias_act(x, self.bias.to(x.dtype), clamp=self.conv_clamp)
        return x


# ----------------------------------------------------------------------------
@persistence.persistent_class
# ç”¨äºç”Ÿæˆç‰¹å®šåˆ†è¾¨ç‡çš„å›¾åƒï¼Œå¹¶ç»“åˆå¤šç§æ¶æ„æ¥æ§åˆ¶æ•°æ®æµçš„æ–¹å¼ã€‚é€šè¿‡ä¸€ç³»åˆ—å·ç§¯ã€è·³è·ƒè¿æ¥ï¼ˆskip connectionsï¼‰å’Œç‰¹å¾æ˜ å°„ï¼ˆRGB è¾“å‡ºï¼‰æ¥å¤„ç†è¾“å…¥ç‰¹å¾å›¾ï¼Œå¹¶è¾“å‡ºåˆæˆåçš„ç‰¹å¾å›¾

class SynthesisBlock(torch.nn.Module):
    def __init__(self,
                 in_channels,  # Number of input channels, 0 = first block.è¾“å…¥ä¸ºå¸¸æ•°ç‰¹å¾å›¾
                 out_channels,  # Number of output channels.å†³å®šäº†ç»è¿‡è¿™ä¸ªå—åè¾“å‡ºç‰¹å¾å›¾çš„é€šé“æ•°
                 w_dim,  # Intermediate latent (W) dimensionality.ç”¨äºæ§åˆ¶ç‰¹å¾å›¾çš„æ ·å¼
                 resolution,  # Resolution of this block.
                 img_channels,  # Number of output colorå›¾åƒ channels.
                 is_last,  # Is this the last block?
                 architecture='skip',  # Architecture: 'orig', 'skip', 'resnet'.
                 resample_filter=[1, 3, 3, 1],  # Low-pass filter to apply when resampling activations.ç”¨äºå¤„ç†å·ç§¯åçš„ç‰¹å¾å›¾
                 conv_clamp=None,
                 # Clamp the output of convolution layers to +-X, None = disable clamping.å°†å·ç§¯è¾“å‡ºé™åˆ¶åœ¨ +-X çš„èŒƒå›´å†…ï¼Œé¿å…æ•°å€¼æº¢å‡º
                 use_fp16=False,  # Use FP16 for this block?
                 fp16_channels_last=False,  # Use channels-last memory format with FP16?å†³å®šæ˜¯å¦ä½¿ç”¨ channels_last çš„å†…å­˜æ ¼å¼ã€‚
                 **layer_kwargs,  # Arguments for SynthesisLayer.
                 ):
        assert architecture in ['orig', 'skip', 'resnet']
        super().__init__()
        self.in_channels = in_channels
        self.w_dim = w_dim
        self.resolution = resolution
        self.img_channels = img_channels
        self.is_last = is_last
        self.architecture = architecture
        self.use_fp16 = use_fp16
        self.channels_last = (use_fp16 and fp16_channels_last)
        self.register_buffer('resample_filter', upfirdn2d.setup_filter(resample_filter))
        self.num_conv = 0
        self.num_torgb = 0
        self.res_ffc = {4: 0, 8: 0, 16: 0, 32: 1, 64: 1, 128: 1, 256: 1, 512: 1}

        if in_channels != 0 and resolution >= 8:
            self.ffc_skip = nn.ModuleList()  # åˆ›å»ºä¸€ç»„ FFCSkipLayer å±‚ï¼Œç”¨äºåœ¨ä¸åŒåˆ†è¾¨ç‡ä¸‹æ·»åŠ å…¨å±€è·³è·ƒè¿æ¥ã€‚res_ffc æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œç”¨äºç¡®å®šä¸åŒåˆ†è¾¨ç‡ä¸‹è·³è·ƒè¿æ¥çš„æ•°é‡
            for _ in range(self.res_ffc[resolution]):
                # print(resolution)
                self.ffc_skip.append(FFCSkipLayer(dim=out_channels))

        if in_channels == 0:  # ç”¨å¸¸æ•°å¼ é‡ä½œä¸ºè¾“å…¥
            self.const = torch.nn.Parameter(torch.randn([out_channels, resolution, resolution]))

        if in_channels != 0:
            # ç¬¬ä¸€ä¸ªå·ç§¯å±‚ã€‚å®ƒè¿›è¡Œä¸Šé‡‡æ ·ï¼ˆup=2ï¼‰æ“ä½œï¼Œä½¿ç‰¹å¾å›¾ä»è¾ƒä½åˆ†è¾¨ç‡æå‡åˆ°è¾ƒé«˜åˆ†è¾¨ç‡ï¼›conv0 æ˜¯ä¸€ä¸ª SynthesisLayer
            self.conv0 = SynthesisLayer(in_channels, out_channels, w_dim=w_dim * 3, resolution=resolution, up=2,
                                        resample_filter=resample_filter, conv_clamp=conv_clamp,
                                        channels_last=self.channels_last, **layer_kwargs)
            self.num_conv += 1
        # ç¬¬äºŒä¸ªå·ç§¯å±‚ï¼Œå®ƒç»§ç»­å¤„ç†è¾“å‡ºç‰¹å¾å›¾
        self.conv1 = SynthesisLayer(out_channels, out_channels, w_dim=w_dim * 3, resolution=resolution,
                                    conv_clamp=conv_clamp, channels_last=self.channels_last, **layer_kwargs)
        self.num_conv += 1

        if is_last or architecture == 'skip':  # ç”Ÿæˆ RGB è¾“å‡ºå±‚ã€‚è¿™ä¸€å±‚å°†ç‰¹å¾å›¾è½¬åŒ–ä¸º RGB å›¾åƒã€‚
            self.torgb = ToRGBLayer(out_channels, img_channels, w_dim=w_dim * 3,
                                    conv_clamp=conv_clamp, channels_last=self.channels_last)
            self.num_torgb += 1

        if in_channels != 0 and architecture == 'resnet':  # skip ç”¨äºåˆ›å»ºæ®‹å·®è¿æ¥ï¼Œå®ƒé€šè¿‡ä¸€ä¸ª 1x1 å·ç§¯å¯¹è¾“å…¥è¿›è¡Œå¤„ç†ï¼Œå¹¶åœ¨åˆ†è¾¨ç‡ä¸Šé‡‡æ ·åä¸è¾“å‡ºç›¸åŠ 
            self.skip = Conv2dLayer(in_channels, out_channels, kernel_size=1, bias=False, up=2,
                                    resample_filter=resample_filter, channels_last=self.channels_last)

        self.eca = ECALayer()  # 1+++åŠ å…¥ ECA æ¨¡å—
        self.depthwise_separable = DepthwiseSeparableConv(out_channels, out_channels, alpha=0.5)  # 7+++æ·±åº¦å¯åˆ†ç¦»å·ç§¯


    def forward(self, x, mask, feats, img, ws, fname=None, force_fp32=False, fused_modconv=None, **layer_kwargs):
        # xè¾“å…¥ç‰¹å¾å›¾ã€‚å¦‚æœè¿™æ˜¯ç¬¬ä¸€ä¸ªå—ï¼Œåˆ™xæ˜¯æ’å®šè¾“å…¥ï¼›å¦åˆ™ä¸ºå‰ä¸€å±‚ä¼ é€’çš„ç‰¹å¾å›¾ï¼›feats: å‰ä¸€å±‚ç”Ÿæˆçš„ç‰¹å¾å›¾ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ç”¨äºè·³è·ƒè¿æ¥ï¼›ws: æ½œåœ¨å˜é‡Wçš„åˆ—è¡¨ï¼Œç”¨äºè°ƒåˆ¶å·ç§¯æ“ä½œä¸­çš„ç‰¹å¾å›¾
        dtype = torch.float16 if self.use_fp16 and not force_fp32 else torch.float32  #x:8,512,4,4,folat32
        memory_format = torch.channels_last if self.channels_last and not force_fp32 else torch.contiguous_format  # å†³å®šå¼ é‡çš„å†…å­˜å¸ƒå±€
        if fused_modconv is None:
            with misc.suppress_tracer_warnings():  # this value will be treated as a constant
                fused_modconv = (not self.training) and (dtype == torch.float32 or int(x.shape[0]) == 1)

        x = x.to(dtype=dtype, memory_format=memory_format)  # 8 512 4 4
        x_skip = feats[self.resolution].clone().to(dtype=dtype, memory_format=memory_format)  # 8 512 8 8
        # ä» feats ä¸­è·å–ä¸å½“å‰åˆ†è¾¨ç‡åŒ¹é…çš„ç‰¹å¾å›¾ï¼Œå¹¶å°†å…¶å¤åˆ¶ä¸º x_skipï¼Œåé¢å¯èƒ½åœ¨è·³è·ƒè¿æ¥æˆ– FFC æ“ä½œä¸­ä½¿ç”¨
        # Main layers.
        if self.in_channels == 0:
            x = self.conv1(x, ws[1], fused_modconv=fused_modconv, **layer_kwargs)

            x = self.eca(x.to(dtype=dtype))  #1+++ åœ¨ç¬¬ä¸€ä¸ªå·ç§¯ååº”ç”¨ ECA0
            x = self.depthwise_separable(x)

        elif self.architecture == 'resnet':  # é€šè¿‡ skip è·³è·ƒè¿æ¥ç”Ÿæˆæ®‹å·®åˆ†æ”¯ y
            y = self.skip(x, gain=np.sqrt(0.5))
            x = self.conv0(x, ws[0].clone(), fused_modconv=fused_modconv, **layer_kwargs)  # æ‰§è¡Œ conv0 å·ç§¯å±‚ï¼Œå°† ws[0] ç”¨äºç‰¹å¾è°ƒåˆ¶

            # x = self.eca(x.to(dtype=dtype))  # 1+++ åœ¨ conv0 ååº”ç”¨ ECA0
            # x = self.depthwise_separable(x)  # 7+++ åŠ å…¥æ·±åº¦å¯åˆ†ç¦»å·ç§¯


            if len(self.ffc_skip) > 0:  # å¦‚æœå­˜åœ¨ ffc_skip å±‚ï¼Œæ’å€¼ mask ä»¥åŒ¹é… x_skip çš„å¤§å°ï¼Œå°† x å’Œ x_skip ç›¸åŠ ï¼Œç„¶åé€šè¿‡ ffc_skip å±‚å¤„ç†ç»“æœ
                mask = F.interpolate(mask, size=x_skip.shape[2:], )
                z = x + x_skip
                for fres in self.ffc_skip:
                    z = fres(z, mask)
                x = x + z
            else:  # æ‰§è¡Œ conv1ï¼Œå¹¶å°† x ä¸æ®‹å·®è¿æ¥ y è¿›è¡ŒåŠ å’Œ
                x = x + x_skip
            x = self.conv1(x, ws[1].clone(), fused_modconv=fused_modconv, gain=np.sqrt(0.5), **layer_kwargs)

            # x = self.eca(x.to(dtype=dtype))  # åœ¨  1+++conv1 ååº”ç”¨ ECA0
            # x = self.depthwise_separable(x)  # 7+++ åŠ å…¥æ·±åº¦å¯åˆ†ç¦»å·ç§¯0

            x = y.add_(x)
        else:  # æ‰§è¡Œ conv0 å¹¶å°†ç»“æœä¸ x_skip ç›¸åŠ ï¼ˆå¦‚æœå­˜åœ¨ ffc_skipï¼Œåˆ™è¿›è¡Œç›¸åº”çš„æ“ä½œ1

            x = self.conv0(x, ws[0].clone(), fused_modconv=fused_modconv, **layer_kwargs)  # 8 512 8 8

            x = self.eca(x.to(dtype=dtype))  # 1+++ åœ¨ conv0 ååº”ç”¨ ECA1
            x = self.depthwise_separable(x)  # 7+++ åŠ å…¥æ·±åº¦å¯åˆ†ç¦»å·ç§¯    å¯ä»¥åšæ¶ˆè

            if len(self.ffc_skip) > 0:  # 32 64 128 256
                mask = F.interpolate(mask, size=x_skip.shape[2:], )
                z = x + x_skip

                for fres in self.ffc_skip:
                    z = fres(z, mask)
                x = x + z
            else:
                x = x + x_skip

            x = self.conv1(x, ws[1].clone(), fused_modconv=fused_modconv, **layer_kwargs)
            x = self.eca(x.to(dtype=dtype))  # åœ¨ 1+++ conv1 ååº”ç”¨ ECA1
            x = self.depthwise_separable(x)  # 7+++ åŠ å…¥æ·±åº¦å¯åˆ†ç¦»å·ç§¯

        # ToRGB.
        if img is not None:     # 111
            misc.assert_shape(img, [None, self.img_channels, self.resolution // 2, self.resolution // 2])
            img = upfirdn2d.upsample2d(img, self.resample_filter)
        if self.is_last or self.architecture == 'skip':  # 111
            y = self.torgb(x, ws[2].clone(), fused_modconv=fused_modconv)
            y = y.to(dtype=torch.float32, memory_format=torch.contiguous_format)
            img = img.add_(y) if img is not None else y  # åœ¨ç”Ÿæˆçš„RGBå›¾åƒyä¸­,å¦‚æœå·²ç»å­˜åœ¨å›¾åƒï¼Œåˆ™å°†å…¶ä¸imgåŠ å’Œï¼›å¦åˆ™ç”¨yä¸ºimg

        x = x.to(dtype=dtype)
        assert x.dtype == dtype
        assert img is None or img.dtype == torch.float32
        return x, img  # è¿”å›ç‰¹å¾å›¾ x å’Œæœ€ç»ˆçš„å›¾åƒ imgã€‚x ä½¿ç”¨åŸå§‹æ•°æ®ç±»å‹ï¼ˆå¯èƒ½ä¸º FP16ï¼‰ï¼Œè€Œ img æ€»æ˜¯ä»¥ torch.float32 ç±»å‹è¿”å›

# ----------------------------------------------------------------------------

@persistence.persistent_class
# ä»æ½œåœ¨å‘é‡ Z å¼€å§‹ï¼Œå°†å…¶æ˜ å°„ä¸ºç‰¹å¾å›¾ï¼Œä½¿ç”¨å·ç§¯å±‚è¿›è¡Œç‰¹å¾æå–ï¼Œå¹¶é€šè¿‡é£æ ¼è°ƒåˆ¶æ§åˆ¶ç”Ÿæˆå›¾åƒçš„é£æ ¼ã€‚å®ƒé€šè¿‡è·³è·ƒè¿æ¥å’Œå¤šå±‚å·ç§¯é€æ¸ç”Ÿæˆç‰¹å¾å›¾ï¼Œæœ€ç»ˆåœ¨ skip æ¶æ„ä¸­ç”Ÿæˆ RGB å›¾åƒ
# ç”¨äºåœ¨ç”Ÿæˆå™¨çš„èµ·å§‹é˜¶æ®µç”Ÿæˆå›¾åƒç‰¹å¾å’Œæœ€ç»ˆå›¾åƒã€‚
class SynthesisForeword(torch.nn.Module):
    def __init__(self,
                 z_dim,  # Output Latent (Z) dimensionality.æ½œåœ¨å‘é‡ Z çš„ç»´åº¦ï¼Œå®šä¹‰äº†ç”Ÿæˆå›¾åƒçš„ç‰¹å¾
                 resolution,  # Resolution of this block.
                 in_channels,  # è¾“å…¥ç‰¹å¾å›¾çš„é€šé“æ•°ã€‚
                 img_channels,  # Number of input color channels.
                 architecture='skip',  # Architecture: 'orig', 'skip', 'resnet'.
                 activation='lrelu',  # Activation function: 'relu', 'lrelu', etc.ç”¨äºå·ç§¯å±‚çš„æ¿€æ´»

                 ):
        super().__init__()
        self.in_channels = in_channels
        self.z_dim = z_dim
        self.resolution = resolution
        self.img_channels = img_channels
        self.architecture = architecture
        # å¤„ç†z_dimçš„æ½œåœ¨å‘é‡ï¼Œå°†å…¶ä»[batch_size, z_dim]è½¬æ¢ä¸ºä¸€ä¸ªå¤§å°[batch_size, (z_dim // 2) * 4 * 4]çš„å‘é‡;å°†æ½œåœ¨å‘é‡æ‰©å±•ä¸ºå°åˆ†è¾¨ç‡ï¼ˆ4x4ï¼‰çš„ç‰¹å¾å›¾ï¼ŒåŒæ—¶åº”ç”¨æ¿€æ´»å‡½æ•°
        self.fc = FullyConnectedLayer(self.z_dim, (self.z_dim // 2) * 4 * 4, activation=activation)
        # ç”¨äºå°†æ‰©å±•çš„ç‰¹å¾å›¾è¿›ä¸€æ­¥å·ç§¯å¤„ç†ï¼Œæå‡å›¾åƒçš„è´¨é‡,è¯¥å·ç§¯å±‚é€šè¿‡å°†ç‰¹å¾å›¾ä»è¾“å…¥é€šé“å·ç§¯åˆ°è¾“å‡ºé€šé“ï¼ŒåŒæ—¶ä½¿ç”¨é£æ ¼è°ƒåˆ¶ï¼ˆåŸºäº ws å‘é‡ï¼‰æ¥æ§åˆ¶å·ç§¯çš„è¡Œä¸º
        self.conv = SynthesisLayer(self.in_channels, self.in_channels, w_dim=(z_dim // 2) * 3, resolution=4)

        if architecture == 'skip':  # å¯ç”¨ ToRGBLayerï¼Œå°†å·ç§¯å±‚è¾“å‡ºçš„ç‰¹å¾å›¾è½¬æ¢ä¸º RGB å›¾åƒ
            self.torgb = ToRGBLayer(self.in_channels, self.img_channels, kernel_size=1, w_dim=(z_dim // 2) * 3)

    def forward(self, x, ws, feats, img, force_fp32=False):
        misc.assert_shape(x, [None, self.z_dim])  # [NC]æ£€æŸ¥è¾“å…¥xçš„å½¢çŠ¶æ˜¯å¦ä¸º[batch_size, z_dim]ã€‚
        _ = force_fp32  # unused
        dtype = torch.float32
        memory_format = torch.contiguous_format

        x_global = x.clone()  # å°†æ½œåœ¨å‘é‡xå¤åˆ¶ä¸ºx_globalï¼Œä»¥ä¾¿ç”¨äºé£æ ¼è°ƒåˆ¶
        # ToRGB.
        x = self.fc(x)  # ä½¿ç”¨å…¨è¿æ¥å±‚ fc å°†æ½œåœ¨å‘é‡ x æ˜ å°„åˆ°å¤§å°ä¸º z_dim // 2 é€šé“ã€4x4 åˆ†è¾¨ç‡çš„ç‰¹å¾å›¾
        x = x.view(-1, self.z_dim // 2, 4, 4)  # ä½¿ç”¨ view å°†è¾“å‡ºçš„ 1D å¼ é‡è½¬æ¢ä¸ºå½¢çŠ¶ä¸º [batch_size, z_dim // 2, 4, 4] çš„ 4D å¼ é‡
        x = x.to(dtype=dtype, memory_format=memory_format)

        # Main layers.
        x_skip = feats[4].clone()  # ä» feats ä¸­è·å–ä¸åˆ†è¾¨ç‡ 4x4 å¯¹åº”çš„è·³è·ƒè¿æ¥ç‰¹å¾å›¾ x_skip
        x = x + x_skip  # å°† x_skip å’Œ x è¿›è¡Œç›¸åŠ ï¼Œè¿™æ˜¯ä¸€ç§è·³è·ƒè¿æ¥æœºåˆ¶ï¼Œå…è®¸ä¸åŒå±‚æ¬¡çš„ç‰¹å¾å›¾ç›¸äº’èåˆã€‚

        mod_vector = []  # mod_vector ç”¨äºé£æ ¼è°ƒåˆ¶ã€‚mod_vector æ˜¯ç”± ws ä¸­çš„ç‰¹å®šæ½œåœ¨å˜é‡å’Œ x_global ç»„æˆ
        mod_vector.append(ws[:, 0])  # ç¬¬ä¸€ä¸ª mod_vector æ˜¯ ws[:, 0] å’Œ x_global çš„æ‹¼æ¥
        mod_vector.append(x_global.clone())
        mod_vector = torch.cat(mod_vector, dim=1)

        x = self.conv(x, mod_vector)  # ç”¨ mod_vector è°ƒåˆ¶ conv å·ç§¯å±‚çš„æƒé‡ï¼Œå¯¹ç‰¹å¾å›¾è¿›è¡Œå·ç§¯å¤„ç†

        mod_vector = []
        mod_vector.append(ws[:, 2 * 2 - 3])  # ç¬¬äºŒä¸ª mod_vector æ˜¯ ws[:, 2*2-3] å’Œ x_global çš„æ‹¼æ¥
        mod_vector.append(x_global.clone())
        mod_vector = torch.cat(mod_vector, dim=1)

        if self.architecture == 'skip':  # è°ƒç”¨ torgb å°†ç‰¹å¾å›¾è½¬æ¢ä¸º RGB å›¾åƒ img
            img = self.torgb(x, mod_vector)
            img = img.to(dtype=torch.float32, memory_format=torch.contiguous_format)

        assert x.dtype == dtype
        return x, img


# ----------------------------------------------------------------------------

@persistence.persistent_class
# origï¼ˆä¼ ç»Ÿæ¶æ„ï¼‰:è¾“å…¥ -> conv0 -> conv1 -> è¾“å‡º
# skipï¼ˆè·³è·ƒè¿æ¥æ¶æ„ï¼‰:è¾“å…¥ -> fromrgb -> conv0 -> conv1 -> è·³è·ƒåˆ°è¾“å‡º
# resnetï¼ˆæ®‹å·®æ¶æ„ï¼‰:è¾“å…¥ -> skip -> conv0 -> conv1 -> æ®‹å·®ç›¸åŠ  -> è¾“å‡º
# ä»å›¾åƒç‰¹å¾ä¸­æå–ä¿¡æ¯ï¼Œå¹¶åˆ¤æ–­è¾“å…¥çš„å›¾åƒæ˜¯å¦æ˜¯çœŸå®å›¾åƒæˆ–ç”Ÿæˆçš„å›¾åƒã€‚è¯¥æ¨¡å—æ”¯æŒä¸åŒæ¶æ„ ('orig', 'skip', 'resnet')ï¼Œå¹¶é€šè¿‡å·ç§¯æ“ä½œé€æ­¥ä¸‹é‡‡æ ·å›¾åƒã€‚
class DiscriminatorBlock(torch.nn.Module):
    def __init__(self,
                 in_channels,  # Number of input channels, 0 = first block.
                 tmp_channels,  # Number of intermediate channels.ä¸­é—´å·ç§¯å±‚çš„é€šé“æ•°ã€‚é€šå¸¸ç”¨äºæå–å’Œè½¬æ¢ç‰¹å¾
                 out_channels,  # Number of output channels.
                 resolution,  # Resolution of this block.
                 img_channels,  # Number of input color channels.
                 first_layer_idx,  # Index of the first layer. å½“å‰å±‚çš„ç´¢å¼•ï¼Œç”¨äºåœ¨å†»ç»“å±‚æ•°ï¼ˆfreeze_layersï¼‰çš„åˆ¤æ–­è¿‡ç¨‹ä¸­ï¼Œç¡®å®šå“ªäº›å±‚æ˜¯å¯è®­ç»ƒçš„ã€‚
                 architecture='resnet',  # Architecture: 'orig', 'skip', 'resnet'.
                 activation='lrelu',  # Activation function: 'relu', 'lrelu', etc.
                 resample_filter=[1, 3, 3, 1],  # Low-pass filter to apply when resampling activations.ç”¨äºå‡å°‘ä¿¡æ¯ä¸¢å¤±
                 conv_clamp=None,
                 # Clamp the output of convolution layers to +-X, None = disable clamping.ç”¨äºå°†å·ç§¯è¾“å‡ºé™åˆ¶åœ¨æŒ‡å®šçš„èŒƒå›´å†…ï¼Œé˜²æ­¢æ•°å€¼æº¢å‡ºã€‚å¦‚æœä¸º Noneï¼Œåˆ™ä¸è¿›è¡Œé™åˆ¶ã€‚
                 use_fp16=False,  # Use FP16 for this block?
                 fp16_channels_last=False,  # Use channels-lastå†…å­˜å¸ƒå±€ï¼ˆä¼˜åŒ–å†…å­˜è®¿é—®æ•ˆç‡ memory format with FP16?
                 freeze_layers=0,  # Freeze-D: Number of layers to freeze.å†»ç»“å‰ n å±‚çš„å‚æ•°ï¼Œä¸è¿›è¡Œè®­ç»ƒï¼Œå¯ä»¥ç”¨æ¥æé«˜æ¨¡å‹çš„ç¨³å®šæ€§
                 ):
        assert in_channels in [0, tmp_channels]
        assert architecture in ['orig', 'skip', 'resnet']
        super().__init__()
        self.in_channels = in_channels
        self.resolution = resolution
        self.img_channels = img_channels + 1
        self.first_layer_idx = first_layer_idx
        self.architecture = architecture
        self.use_fp16 = use_fp16
        self.channels_last = (use_fp16 and fp16_channels_last)
        self.register_buffer('resample_filter', upfirdn2d.setup_filter(resample_filter))

        self.num_layers = 0

        def trainable_gen():  # ä¸€ä¸ªç”Ÿæˆå™¨å‡½æ•°ï¼Œç”¨äºå†³å®šæ¯ä¸€å±‚æ˜¯å¦æ˜¯å¯è®­ç»ƒçš„ã€‚å½“æŸä¸€å±‚çš„ç´¢å¼•å¤§äºç­‰äº freeze_layers æ—¶ï¼Œè¯¥å±‚æ˜¯å¯è®­ç»ƒçš„ï¼›å¦åˆ™ï¼Œå±‚çš„å‚æ•°å°†è¢«å†»ç»“
            while True:
                layer_idx = self.first_layer_idx + self.num_layers
                trainable = (layer_idx >= freeze_layers)
                self.num_layers += 1
                yield trainable

        trainable_iter = trainable_gen()

        if in_channels == 0 or architecture == 'skip':
            # å¤„ç†è¾“å…¥å›¾åƒçš„ç¬¬ä¸€å±‚å·ç§¯ã€‚fromrgb å±‚å°†æŠŠè¾“å…¥çš„ RGB å›¾åƒï¼ˆæˆ–åŒ…å« mask çš„å›¾åƒï¼‰é€šè¿‡ 1x1 å·ç§¯è½¬æ¢ä¸ºå…·æœ‰tmp_channels æ•°é‡çš„ä¸­é—´ç‰¹å¾å›¾ã€‚
            self.fromrgb = Conv2dLayer(self.img_channels, tmp_channels, kernel_size=1, activation=activation,
                                       trainable=next(trainable_iter), conv_clamp=conv_clamp,
                                       channels_last=self.channels_last)
        # ä¸€ä¸ªæ ‡å‡†çš„ 3x3 å·ç§¯å±‚ï¼Œè¾“å…¥ä¸º tmp_channels é€šé“ï¼Œè¾“å‡ºä¹Ÿæ˜¯ tmp_channels é€šé“ã€‚è¯¥å±‚åœ¨ç»è¿‡å·ç§¯åä¼šåº”ç”¨æ¿€æ´»å‡½æ•°ï¼ˆä¾‹å¦‚ lrelu
        self.conv0 = Conv2dLayer(tmp_channels, tmp_channels, kernel_size=3, activation=activation,
                                 trainable=next(trainable_iter), conv_clamp=conv_clamp,
                                 channels_last=self.channels_last)
        # ç¬¬äºŒä¸ª 3x3 å·ç§¯å±‚ï¼Œä¸conv0ç±»ä¼¼ï¼Œè¿™å±‚åŒæ—¶ä¼šä¸‹é‡‡æ ·è¾“å…¥ç‰¹å¾å›¾ï¼ˆé€šè¿‡down=2ï¼‰ï¼Œå°†åˆ†è¾¨ç‡é™ä½ä¸€åŠï¼Œå¹¶å°†è¾“å‡ºé€šé“è½¬æ¢ä¸ºout_channelsã€‚è¿™ä¸€æ­¥é€šè¿‡å·ç§¯å’Œä¸‹é‡‡æ ·æ¥æå–é«˜å±‚æ¬¡çš„ç‰¹å¾
        self.conv1 = Conv2dLayer(tmp_channels, out_channels, kernel_size=3, activation=activation, down=2,
                                 trainable=next(trainable_iter), resample_filter=resample_filter, conv_clamp=conv_clamp,
                                 channels_last=self.channels_last)
        # ä¸€ä¸ª 1x1 çš„å·ç§¯å±‚ï¼Œç”¨äºå®ç°æ®‹å·®è¿æ¥ï¼Œå°†è¾“å…¥ç›´æ¥ä¼ é€’åˆ°ä¸‹ä¸€ä¸ªæ¨¡å—ã€‚è¯¥æ“ä½œçš„ç›®çš„åœ¨äºé€šè¿‡ down=2 è¿›è¡Œä¸‹é‡‡æ ·ï¼Œå¹¶ä¸ä¸»è·¯å¾„çš„å·ç§¯ç»“æœç›¸åŠ 
        if architecture == 'resnet':
            self.skip = Conv2dLayer(tmp_channels, out_channels, kernel_size=1, bias=False, down=2,
                                    trainable=next(trainable_iter), resample_filter=resample_filter,
                                    channels_last=self.channels_last)

    def forward(self, x, img, force_fp32=False):  # è´Ÿè´£åœ¨åˆ¤åˆ«å™¨ä¸­å¯¹è¾“å…¥ç‰¹å¾å›¾ï¼ˆxï¼‰å’Œå›¾åƒï¼ˆimgï¼‰è¿›è¡Œå¤„ç†ï¼Œå¹¶å°†å…¶ä¼ é€’ç»™å·ç§¯å±‚ä»¥æå–ç‰¹å¾
        dtype = torch.float16 if self.use_fp16 and not force_fp32 else torch.float32
        memory_format = torch.channels_last if self.channels_last and not force_fp32 else torch.contiguous_format

        # Input.ç¡®ä¿å…¶å½¢çŠ¶ä¸º [batch_size, in_channels, resolution, resolution]ï¼Œç„¶åå°†è¾“å…¥ç‰¹å¾å›¾ x è½¬æ¢ä¸ºç›¸åº”çš„æ•°æ®ç±»å‹ (dtype) å’Œå†…å­˜æ ¼å¼ (memory_format
        if x is not None:
            misc.assert_shape(x, [None, self.in_channels, self.resolution, self.resolution])
            x = x.to(dtype=dtype, memory_format=memory_format)

        # FromRGB.fromRGBå±‚å°†RGBå›¾åƒè¾“å…¥è½¬æ¢ä¸ºç‰¹å¾å›¾ï¼Œç”¨äºç¬¬ä¸€ä¸ªå·ç§¯å—çš„è¾“å…¥
        if self.in_channels == 0 or self.architecture == 'skip':  # å›¾åƒè¾“å…¥ä¼šç»è¿‡ fromRGB å±‚
            misc.assert_shape(img, [None, self.img_channels, self.resolution,
                                    self.resolution])  # æ£€æŸ¥imgå½¢çŠ¶ï¼Œç¡®ä¿å…¶ç»´åº¦ä¸º[batch_size, img_channels, resolution, resolution]
            img = img.to(dtype=dtype, memory_format=memory_format)  # å°†å›¾åƒè½¬æ¢ä¸º dtype å’Œ memory_format
            y = self.fromrgb(img)  # é€šè¿‡ fromrgb å±‚æå–å›¾åƒç‰¹å¾ï¼Œå¹¶å°†æå–çš„ç‰¹å¾ä¸è¾“å…¥ç‰¹å¾ x ç›¸åŠ ï¼ˆå¦‚æœ x ä¸ä¸º Noneï¼‰
            x = x + y if x is not None else y
            img = upfirdn2d.downsample2d(img,
                                         self.resample_filter) if self.architecture == 'skip' else None  # è¿˜ä¼šå°†å›¾åƒé€šè¿‡downå±‚ä¸‹é‡‡æ ·ï¼Œç”¨äºåç»­è·³è·ƒè¿æ¥

        # Main layers.
        if self.architecture == 'resnet':  # é¢å¤–æ·»åŠ æ®‹å·®è·¯å¾„ï¼ˆè·³è·ƒè¿æ¥
            y = self.skip(x, gain=np.sqrt(0.5))  # é€šè¿‡ skip å±‚å¯¹è¾“å…¥ç‰¹å¾è¿›è¡Œ 1x1 å·ç§¯å’Œä¸‹é‡‡æ ·æ“ä½œï¼Œå°†å…¶å­˜å‚¨åœ¨å˜é‡ y ä¸­ã€‚
            x = self.conv0(x)  # å¯¹ x é€šè¿‡ conv0 å’Œ conv1 ä¸¤ä¸ªå·ç§¯å±‚å¤„ç†ï¼Œæ¯æ¬¡éƒ½ä¼šè¿›è¡Œå·ç§¯å’Œæ¿€æ´»ï¼Œå¹¶ä½¿ç”¨ gain=np.sqrt(0.5) æ¥å¹³è¡¡è¾“å‡º
            x = self.conv1(x, gain=np.sqrt(0.5))
            x = y.add_(x)  # å°†æ®‹å·®è·¯å¾„ y å’Œä¸»è·¯å¾„çš„ç»“æœ x ç›¸åŠ ï¼Œå®ç°æ®‹å·®è¿æ¥ã€‚
        else:
            x = self.conv0(x)
            x = self.conv1(x)

        assert x.dtype == dtype
        return x, img


# ----------------------------------------------------------------------------

@persistence.persistent_class
# å¸®åŠ©æ¨¡å‹åŒºåˆ†çœŸå®å›¾åƒå’Œç”Ÿæˆå›¾åƒã€‚é€šè¿‡å¼•å…¥å°æ‰¹é‡æ ‡å‡†å·®ï¼ˆminibatch standard deviationç‰¹å¾æ¥å¢å¼ºæ¨¡å‹å¯¹å°æ‰¹é‡æ ·æœ¬é—´çš„ç»Ÿè®¡å·®å¼‚çš„æ•æ„Ÿæ€§ï¼Œå¸®åŠ©æ¨¡å‹æ›´å¥½åœ°æ£€æµ‹ç”Ÿæˆå›¾åƒä¸­çš„ä¸ä¸€è‡´æ€§
class MinibatchStdLayer(torch.nn.Module):
    # group_sizeï¼šå°†å°æ‰¹é‡ä¸­çš„æ ·æœ¬åˆ†ä¸ºè‹¥å¹²ç»„ï¼Œæ¯ç»„è®¡ç®—ä¸€æ¬¡æ ‡å‡†å·®;num_channelsï¼šæ¯ä¸ªç»„ä¸­é¢å¤–ç”Ÿæˆçš„ç‰¹å¾å›¾æ•°é‡ï¼Œé»˜è®¤ä¸º 1ï¼Œé€šå¸¸ç”¨äºè¡¨ç¤ºä¸€ç»„çš„æ ‡å‡†å·®
    def __init__(self, group_size, num_channels=1):
        super().__init__()
        self.group_size = group_size
        self.num_channels = num_channels

    def forward(self, x):
        N, C, H, W = x.shape  # N è¡¨ç¤º batch sizeï¼ˆå°æ‰¹é‡å¤§å°ï¼‰ï¼ŒC æ˜¯è¾“å…¥ç‰¹å¾å›¾çš„é€šé“æ•°ï¼ŒH å’Œ W åˆ†åˆ«æ˜¯ç‰¹å¾å›¾çš„é«˜åº¦å’Œå®½åº¦
        with misc.suppress_tracer_warnings():  # as_tensor results are registered as constantsç¡®ä¿ G ä¸ä¼šè¶…è¿‡æ‰¹é‡å¤§å° Nï¼Œå¹¶ä¸”æ ¹æ® self.group_size å‚æ•°å†³å®šæ¯ç»„åŒ…å«çš„æ ·æœ¬æ•°
            G = torch.min(torch.as_tensor(self.group_size), torch.as_tensor(N)) if self.group_size is not None else N
        F = self.num_channels  # å°†è¾“å…¥ x è¿›è¡Œé‡å¡‘ï¼Œå°† batch ä¸­çš„æ ·æœ¬åˆ†æˆ G ç»„ï¼Œå¹¶ä¸”å°†è¾“å…¥é€šé“æ•° C åˆ’åˆ†æˆ F ç»„ï¼Œæ¯ç»„åŒ…å«c = C // F ä¸ªé€šé“ã€‚ç›®çš„æ˜¯ä¸ºæ¯ä¸€ç»„è®¡ç®—æ ‡å‡†å·®
        c = C // F
        # yçš„å½¢çŠ¶æœ€åˆæ˜¯ [G, F, 1, 1]ï¼Œå…¶ä¸­ G æ˜¯ batch å¤§å°ï¼ŒF æ˜¯æ ‡å‡†å·®çš„é€šé“æ•°ã€‚ä½¿ç”¨ y.repeat(G, 1, H, W) å°† y çš„å½¢çŠ¶æ‰©å±•ä¸º [G, F, H, W]
        # ä½¿å¾— y åœ¨é«˜åº¦ï¼ˆHï¼‰å’Œå®½åº¦ï¼ˆWï¼‰ä¸Šä¸è¾“å…¥ç‰¹å¾å›¾ x ä¿æŒä¸€è‡´ã€‚åœ¨é€šé“ç»´åº¦ dim=1 ä¸Šæ‹¼æ¥ï¼Œå½¢æˆå½¢çŠ¶ä¸º [N, C+F, H, W] çš„æ–°ç‰¹å¾å›¾ã€‚
        y = x.reshape(G, -1, F, c, H,
                      W)  # [GnFcHW] Split minibatch N into n groups of size G, and channels C into F groups of size c.
        y = y - y.mean(dim=0)  # [GnFcHW] Subtract mean over group.è®¡ç®—æ¯ç»„é€šé“çš„å‡å€¼ï¼Œä»æ¯ä¸ªæ ·æœ¬ä¸­å‡å»è¯¥å‡å€¼ï¼Œä½¿å…¶ä¸­å¿ƒåŒ–ã€‚è®¡ç®—ç»„å†…çš„ç»Ÿè®¡å·®å¼‚
        y = y.square().mean(dim=0)  # [nFcHW]  Calc variance over group.
        y = (y + 1e-8).sqrt()  # [nFcHW]  Calc stddev over group.å…ˆè®¡ç®—æ–¹å·®ï¼Œå†å–å¹³æ–¹æ ¹å¾—åˆ°æ ‡å‡†å·®ã€‚1e-8 æ˜¯ä¸ºäº†é¿å…æ•°å€¼ä¸ç¨³å®šæ€§ï¼Œå³é˜²æ­¢é™¤ä»¥0
        y = y.mean(dim=[2, 3, 4])  # [nF]     Take average over channels and pixels.å°†æ ‡å‡†å·®åœ¨æ¯ä¸ªé€šé“å’Œåƒç´ ç»´åº¦ä¸Šè¿›è¡Œå¹³å‡ï¼Œå¾—åˆ°[G, F]çš„æ ‡å‡†å·®
        y = y.reshape(-1, F, 1, 1)  # [nF11]   Add missing dimensions. å°†å…¶å˜å½¢ä¸º [G, F, 1, 1]ï¼Œä»¥ä¾¿ç¨åä¸åŸå§‹ç‰¹å¾å›¾æ‹¼æ¥ã€‚
        y = y.repeat(G, 1, H,
                     W)  # [NFHW]   Replicate over group and pixels.å°†yä¸­çš„æ ‡å‡†å·®ç‰¹å¾å›¾é‡å¤ï¼Œç¡®ä¿å…¶å½¢çŠ¶ä¸åŸå§‹è¾“å…¥ç‰¹å¾å›¾xåŒ¹é…ã€‚yçš„å½¢çŠ¶ä¸º [N, F, H, W]å¯ä»¥ä¸è¾“å…¥xè¿›è¡Œé€šé“ç»´åº¦ä¸Šçš„æ‹¼æ¥
        x = torch.cat([x, y], dim=1)  # [NCHW]   Append to input as new channels.
        return x


# ----------------------------------------------------------------------------

@persistence.persistent_class
# å°†ç‰¹å¾å›¾è½¬åŒ–ä¸ºæœ€ç»ˆçš„åˆ¤åˆ«è¾“å‡º
class DiscriminatorEpilogue(torch.nn.Module):
    def __init__(self,
                 in_channels,  # Number of input channels.
                 cmap_dim,  # Dimensionality of mapped conditioning label, 0 = no label.æ¡ä»¶æ ‡ç­¾çš„æ˜ å°„ç»´åº¦ï¼Œç”¨äºæ¡ä»¶ç”Ÿæˆä»»åŠ¡
                 resolution,  # Resolution of this block.
                 img_channels,  # Number of input color channels.
                 architecture='resnet',  # Architecture: 'orig', 'skip', 'resnet'.
                 mbstd_group_size=4,
                 # Group size for the minibatch standard deviation layer, None = entire minibatch.ç”¨äº MinibatchStdLayer çš„ç»„å¤§å°ï¼Œç”¨äºç»Ÿè®¡æ ‡å‡†å·®
                 mbstd_num_channels=1,
                 # Number of features for the minibatch standard deviation layer, 0 = disable.MinibatchStdLayer ç”Ÿæˆçš„ç‰¹å¾é€šé“æ•°
                 activation='lrelu',  # Activation function: 'relu', 'lrelu', etc.
                 conv_clamp=None,
                 # Clamp the output of convolution layers to +-X, None = disable clamping.å·ç§¯å±‚è¾“å‡ºçš„æˆªæ–­èŒƒå›´ï¼Œå¦‚æœè®¾ç½®ä¸º Noneï¼Œåˆ™ä¸è¿›è¡Œæˆªæ–­
                 ):
        assert architecture in ['orig', 'skip', 'resnet']
        super().__init__()
        self.in_channels = in_channels
        self.cmap_dim = cmap_dim
        self.resolution = resolution
        self.img_channels = img_channels
        self.architecture = architecture

        if architecture == 'skip':  # é¢å¤–æ·»åŠ ä¸€ä¸ª fromrgb å±‚ï¼Œç”¨äºå°† RGB å›¾åƒç›´æ¥è½¬åŒ–ä¸ºç‰¹å¾å›¾ã€‚
            self.fromrgb = Conv2dLayer(img_channels, in_channels, kernel_size=1, activation=activation)
        # æ·»åŠ ä¸€ä¸ª MinibatchStdLayerï¼Œç”¨äºè®¡ç®—æ¯ä¸ªå°æ‰¹é‡æ•°æ®çš„æ ‡å‡†å·®ï¼Œå¹¶å°†å…¶ä½œä¸ºé¢å¤–çš„ç»Ÿè®¡ç‰¹å¾æ·»åŠ åˆ°è¾“å…¥ä¸­ã€‚
        self.mbstd = MinibatchStdLayer(group_size=mbstd_group_size,
                                       num_channels=mbstd_num_channels) if mbstd_num_channels > 0 else None
        # å°†è¾“å…¥é€šé“ï¼ˆåŒ…æ‹¬æ ‡å‡†å·®é€šé“ï¼‰è½¬åŒ–ä¸ºè¾“å‡ºç‰¹å¾å›¾ï¼Œå·ç§¯æ ¸å¤§å°ä¸º 3x3ã€‚
        self.conv = Conv2dLayer(in_channels + mbstd_num_channels, in_channels, kernel_size=3, activation=activation,
                                conv_clamp=conv_clamp)
        self.fc = FullyConnectedLayer(in_channels * (resolution ** 2), in_channels,
                                      activation=activation)  # å°†å·ç§¯å±‚è¾“å‡ºçš„ç‰¹å¾å±•å¹³å¹¶è½¬åŒ–ä¸ºå›ºå®šé•¿åº¦çš„å‘é‡
        self.out = FullyConnectedLayer(in_channels,
                                       1 if cmap_dim == 0 else cmap_dim)  # æ ¹æ®æ˜¯å¦å­˜åœ¨cmap_dimï¼Œè¾“å‡ºä¸€ä¸ªæ ‡é‡ï¼ˆè¡¨ç¤ºå¯¹æŠ—æŸå¤±ï¼‰ï¼Œæˆ–æ¡ä»¶æ ‡ç­¾å¯¹åº”çš„å‘é‡ã€‚

    def forward(self, x, img, cmap, force_fp32=False):
        misc.assert_shape(x, [None, self.in_channels, self.resolution, self.resolution])  # [NCHW]
        _ = force_fp32  # unused
        dtype = torch.float32
        memory_format = torch.contiguous_format

        # FromRGB.å°†è¾“å…¥å›¾åƒ img è½¬æ¢ä¸ºç‰¹å¾å›¾ï¼Œå¹¶ä¸è¾“å…¥ç‰¹å¾å›¾ x ç›¸åŠ ã€‚img æ˜¯åŸå§‹è¾“å…¥å›¾åƒï¼Œx æ˜¯æ¥è‡ªå‰ä¸€ä¸ªåˆ¤åˆ«å™¨å—çš„ç‰¹å¾å›¾ã€‚fromrgb å±‚ä½¿ç”¨ä¸€ä¸ª 1x1 çš„å·ç§¯å°†å›¾åƒè½¬åŒ–ä¸ºç‰¹å¾å›¾ï¼Œä¾¿äºä¸å…¶ä»–ç‰¹å¾èåˆ
        x = x.to(dtype=dtype, memory_format=memory_format)
        if self.architecture == 'skip':
            misc.assert_shape(img, [None, self.img_channels, self.resolution, self.resolution])
            img = img.to(dtype=dtype, memory_format=memory_format)
            x = x + self.fromrgb(img)

        # Main layers.
        if self.mbstd is not None:
            x = self.mbstd(x)  # è®¡ç®—å°æ‰¹é‡æ ‡å‡†å·®å¹¶æ·»åŠ åˆ°ç‰¹å¾å›¾ä¸­
        x = self.conv(x)  # é€šè¿‡ä¸€ä¸ª3x3å·ç§¯æ“ä½œå¯¹è¾“å…¥è¿›è¡Œå¤„ç†ï¼Œå¾—åˆ°æ–°çš„ç‰¹å¾å›¾ã€‚å·ç§¯å±‚çš„è¾“å…¥æ˜¯åŠ å…¥äº†æ ‡å‡†å·®ç‰¹å¾å›¾çš„ç‰¹å¾å›¾ï¼Œè¾“å‡ºå…·æœ‰ä¸è¾“å…¥ç›¸åŒçš„ç©ºé—´ç»´åº¦ï¼ˆä½†é€šé“æ•°å¯èƒ½ä¼šä¸åŒ
        x = self.fc(x.flatten(1))  # å°†å·ç§¯å±‚çš„è¾“å‡ºå±•å¹³ä¸ºä¸€ç»´å‘é‡ï¼Œè¾“å…¥å…¨è¿æ¥å±‚ï¼Œå°†å…¶è½¬åŒ–ä¸ºå›ºå®šé•¿åº¦çš„ç‰¹å¾å‘é‡
        x = self.out(x)  # è¾“å‡ºå±‚æ ¹æ®æ˜¯å¦æœ‰æ¡ä»¶æ ‡ç­¾æ¥ç¡®å®šè¾“å‡ºå½¢å¼.cmap_dim > 0,å°†åˆ¤åˆ«å™¨è¾“å‡ºä¸æ¡ä»¶æ ‡ç­¾è¿›è¡Œç‚¹ç§¯ï¼ˆé€šè¿‡ cmap è¿›è¡Œæ¡ä»¶æ ‡ç­¾çš„ä¹˜ç§¯ï¼‰ï¼Œå¾—åˆ°æ¡ä»¶åŒ–çš„åˆ¤åˆ«è¾“å‡º
        # cmap_dim = 0ï¼šè¾“å‡ºä¸€ä¸ªæ ‡é‡ï¼Œè¡¨ç¤ºåˆ¤åˆ«å™¨çš„è¾“å‡ºå€¼ï¼ˆé€šå¸¸æ˜¯å›¾åƒæ˜¯å¦çœŸå®çš„æ¦‚ç‡ï¼‰ã€‚
        # Conditioning.cmap è¡¨ç¤ºæ˜ å°„åçš„æ¡ä»¶å‘é‡ï¼Œå…¶ç»´åº¦ä¸º [N, cmap_dim]ã€‚è¯¥æ¡ä»¶æ ‡ç­¾é€šè¿‡ç‚¹ç§¯ä¸ç‰¹å¾å‘é‡è¿›è¡Œèåˆï¼Œç„¶åè¾“å‡ºä¸€ä¸ªæ ‡é‡ä½œä¸ºæœ€ç»ˆç»“æœ
        if self.cmap_dim > 0:
            misc.assert_shape(cmap, [None, self.cmap_dim])
            x = (x * cmap).sum(dim=1, keepdim=True) * (1 / np.sqrt(self.cmap_dim))

        assert x.dtype == dtype
        return x

# ----------------------------------------------------------------------------
